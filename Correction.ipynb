{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c6ae2b",
   "metadata": {},
   "source": [
    "## Calculate Raw image correction paramters\n",
    "*Author: Haiyun Huang 2025 with Deepseek*\n",
    "\n",
    "This document aims to acquire mathmatically accurate correction parameters for raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003d3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4230b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mvsdk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from huateng_camera_v2_tc_mod import Camera\n",
    "from raw_processing import raw_awb, raw_wb\n",
    "from correction_utils import suppress_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f40857",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPOSURE_TIME = 10 # ms\n",
    "ADC_MAX_LEVEL = 2**12 - 1 # No greater than 65535"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb0289",
   "metadata": {},
   "source": [
    "### 01. Acquiring AWB Correction Parameters\n",
    "The WB process will do:\n",
    "- (optional) extra dBLC, \n",
    "- clipping to per channel max level, \n",
    "- scales the RAW channels to 16bit.\n",
    "\n",
    "Acquiring params including:\n",
    "- (optional) RGB dBLC (after BLC), \n",
    "- RGB gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716ad2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n",
      "RAW Grabbed: img.max(): 4094, img.min(): 32\n"
     ]
    }
   ],
   "source": [
    "# Acquire preview image\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "\n",
    "mycam.open()\n",
    "raw_img = mycam.grab_raw()\n",
    "mycam.close()\n",
    "# img最大值最小值\n",
    "print(f'RAW Grabbed: img.max(): {raw_img.max()}, img.min(): {raw_img.min()}')\n",
    "plt.imshow(raw_img)\n",
    "plt.title('RAW Preview')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f517e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting essential params for acquiring correction params\n",
    "repeats = 100\n",
    "BLC = 32\n",
    "BAYER_PATTERN = 'BGGR'\n",
    "\n",
    "# 白平衡\n",
    "# 定义两个ROI用于自动白平衡\n",
    "# ROI 1 (亮区)\n",
    "x_slice_1 = slice(1440, 1500)\n",
    "y_slice_1 = slice(920, 980)\n",
    "awb_roi_1 = (y_slice_1, x_slice_1) # y,x\n",
    "\n",
    "# ROI 2 (暗区)\n",
    "x_slice_2 = slice(1440, 1500)\n",
    "y_slice_2 = slice(1120, 1180)\n",
    "awb_roi_2 = (y_slice_2, x_slice_2) # y,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a37c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n"
     ]
    }
   ],
   "source": [
    "# Acquire images\n",
    "\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "mycam.open()\n",
    "\n",
    "imgs = []\n",
    "for i in range(repeats):\n",
    "    img = mycam.grab_raw()\n",
    "    imgs.append(img)\n",
    "mycam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad86ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AWB params: (mean ± SE)\n",
      "R gain: 1.8539 ± 0.0003\n",
      "G gain: 1.2618 ± 0.0002\n",
      "B gain: 1.0000 ± 0.0000\n",
      "R dBLC: -14.4534 ± 0.1373\n",
      "G dBLC: -11.8186 ± 0.1712\n",
      "B dBLC: 0.0000 ± 0.0000\n",
      "Copy format: (1.85387511102, 1.26180502111, 1.0, -14.4534427761, -11.8186137314, 0.0)\n",
      "Parameters saved in variable `awb_params`\n"
     ]
    }
   ],
   "source": [
    "# Calculate avg. correction parameters\n",
    "raw_awb_slience = suppress_output(raw_awb)\n",
    "\n",
    "awb_params_list = []\n",
    "for img in imgs:\n",
    "    # basic BLC\n",
    "    img_BLC = img - BLC\n",
    "    # AWB\n",
    "    _, awb_params = raw_awb_slience(img_BLC, awb_roi_1, awb_roi_2, pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "    awb_params_list.append(awb_params)\n",
    "awb_params_np = np.array(awb_params_list)\n",
    "awb_params_avg = np.mean(awb_params_np, axis=0)\n",
    "awb_params_se = np.std(awb_params_np, ddof=1, axis=0)/np.sqrt(repeats)\n",
    "\n",
    "print('Average AWB params: (mean ± SE)')\n",
    "print(f'R gain: {awb_params_avg[0]:.4f} ± {awb_params_se[0]:.4f}')\n",
    "print(f'G gain: {awb_params_avg[1]:.4f} ± {awb_params_se[1]:.4f}')\n",
    "print(f'B gain: {awb_params_avg[2]:.4f} ± {awb_params_se[2]:.4f}')\n",
    "print(f'R dBLC: {awb_params_avg[3]:.4f} ± {awb_params_se[3]:.4f}')\n",
    "print(f'G dBLC: {awb_params_avg[4]:.4f} ± {awb_params_se[4]:.4f}')\n",
    "print(f'B dBLC: {awb_params_avg[5]:.4f} ± {awb_params_se[5]:.4f}')\n",
    "print(f'Copy format: ({', '.join(map(str, awb_params_avg))})')\n",
    "awb_params = tuple(awb_params_avg)\n",
    "print('Parameters saved in variable `awb_params`')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d19fc",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "D65 Room LED Light\n",
    "> Average AWB params: (mean ± SE)\\\n",
    "`R gain`: 1.8722 ± 0.0005\\\n",
    "`G gain`: 1.2736 ± 0.0002\\\n",
    "`B gain`: 1.0000 ± 0.0000\\\n",
    "`R dBLC`: -16.2625 ± 0.2017\\\n",
    "`G dBLC`: -13.0992 ± 0.2143\\\n",
    "`B dBLC`: 0.0000 ± 0.0000\\\n",
    "Copy format: `(1.87217887201, 1.27358336204, 1.0, -16.2625453031, -13.099179932, 0.0)`\n",
    "\n",
    "D50 Sunlike Light (10ms exposure, white patch ~ 3000-4000 DN @ 12bit)\n",
    "> Average AWB params: (mean ± SE)\\\n",
    "`R gain`: 1.6223 ± 0.0003\\\n",
    "`G gain`: 1.3053 ± 0.0002\\\n",
    "`B gain`: 1.0000 ± 0.0000\\\n",
    "`R dBLC`: -5.5832 ± 0.1601\\\n",
    "`G dBLC`: -6.5196 ± 0.1868\\\n",
    "`B dBLC`: 0.0000 ± 0.0000\\\n",
    "Copy format: `(1.62229078895, 1.30534488103, 1.0, -5.58319935118, -6.51955880128, 0.0)`\\\n",
    "Parameters saved in variable `awb_params`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8a97f",
   "metadata": {},
   "source": [
    "### 02. Calculate Forward Matrix\n",
    "Transform colors from device $RGB$ to $XYZ_{D50}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b84986",
   "metadata": {},
   "source": [
    "#### a1. Preparing ColorChecker24 Reference Data\n",
    "Convert reference $Lab_{D50}$ data to $XYZ$ for given illuminant by *Bradford* + *von Keris* method.\n",
    "\n",
    "The reference ColorChecker24 patches are measured under D50 illuminant in $Lab_{D50}$ format\\\n",
    "We need to transform such refernece $Lab$ value to $XYZ$ space under the constraint of D50 illuminant.\n",
    "\n",
    "The layout of CC24: 4 rows, 6 columns. `A1` is at upper left, `F4` is at lower right.\n",
    "\n",
    "多解释一些：\n",
    "1. 对于反射式测试卡，反射率是其本质，而对于传感器，光谱辐照是其本质。\n",
    "2. D50照明定义了照明谱，只有在给定照明谱的情况下，才能拿到光谱辐照，拿到加色性的XYZ值。\n",
    "3. 这也是为什么测试卡用Lab标注值，而不是XYZ，因为XYZ会随着照明不同而改变。但Lab是归一化到白点（*相对*稳定，此为von Kries假设下的方法），并且定义了测量白点是D50（Lab空间需要给定白点才在辐照水平有意义）。\n",
    "4. $XYZ_{D50}$的下标并没有实际意义，因为XYZ空间不依赖白点而存在，只是为了表示是D50照明下获得的值。\n",
    "5. 对于不同白点的转换，常用Bradford比色法，主要是将XYZ值转移到LMS空间后缩放。不同比色法定义的这个转移矩阵$M_A$不同。\n",
    "6. 对于更精确的应用，应当直接从各色块的反射率曲线推导给定光源（如D65）下的XYZ值，而不是用$Lab_{D50}$通过Bradford。 参见：https://babelcolor.com/colorchecker-2.htm#xl_CCP2_images\n",
    "7. 由于新版ColorChecker24没有平均的反射率曲线可用，本文档推荐使用Bradford比色法处理照明非D50的情况。\n",
    "\n",
    "The basic idea is, transforming $XYZ$ to physiologically relavent $LMS$ space, scaling in $LMS$ space (based on *von Kries* hypothesis), and then transform back.\\\n",
    "There are multiple options of matirx for $XYZ$ to $LMS$, probably because of different illuminant spectra,\\\n",
    "including *Identical*, *Bradford* methods, etc.\\\n",
    "See documents of `colour.adaptation.CAT_*` for more methods based on *von Kries* hypothesis.\n",
    "\n",
    "See more mathmatical details:\n",
    "  1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/bradford_e.html\\\n",
    "  2. http://www.brucelindbloom.com/index.html?Eqn_ChromAdapt.html\\\n",
    "\n",
    "For information about XYZ-Lab transformation, see: \n",
    "  1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/colorspace3_e.html\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43292044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the illuminant of the calibration images, CIE 1931 XYZ value.\n",
    "\n",
    "import colour\n",
    "\n",
    "illuminant = colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d75b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1' 'B1' 'C1' 'D1' 'E1' 'F1' 'A2' 'B2' 'C2' 'D2' 'E2' 'F2' 'A3' 'B3' 'C3'\n",
      " 'D3' 'E3' 'F3' 'A4' 'B4' 'C4' 'D4' 'E4' 'F4']\n",
      "[[  3.75400000e+01   1.43700000e+01   1.49200000e+01]\n",
      " [  6.46600000e+01   1.92700000e+01   1.75000000e+01]\n",
      " [  4.93200000e+01  -3.82000000e+00  -2.25400000e+01]\n",
      " [  4.34600000e+01  -1.27400000e+01   2.27200000e+01]\n",
      " [  5.49400000e+01   9.61000000e+00  -2.47900000e+01]\n",
      " [  7.04800000e+01  -3.22600000e+01  -3.70000000e-01]\n",
      " [  6.27300000e+01   3.58300000e+01   5.65000000e+01]\n",
      " [  3.94300000e+01   1.07500000e+01  -4.51700000e+01]\n",
      " [  5.05700000e+01   4.86400000e+01   1.66700000e+01]\n",
      " [  3.01000000e+01   2.25400000e+01  -2.08700000e+01]\n",
      " [  7.17700000e+01  -2.41300000e+01   5.81900000e+01]\n",
      " [  7.15100000e+01   1.82400000e+01   6.73700000e+01]\n",
      " [  2.83700000e+01   1.54200000e+01  -4.98000000e+01]\n",
      " [  5.43800000e+01  -3.97200000e+01   3.22700000e+01]\n",
      " [  4.24300000e+01   5.10500000e+01   2.86200000e+01]\n",
      " [  8.18000000e+01   2.67000000e+00   8.04100000e+01]\n",
      " [  5.06300000e+01   5.12800000e+01  -1.41200000e+01]\n",
      " [  4.95700000e+01  -2.97100000e+01  -2.83200000e+01]\n",
      " [  9.51900000e+01  -1.03000000e+00   2.93000000e+00]\n",
      " [  8.12900000e+01  -5.70000000e-01   4.40000000e-01]\n",
      " [  6.68900000e+01  -7.50000000e-01  -6.00000000e-02]\n",
      " [  5.07600000e+01  -1.30000000e-01   1.40000000e-01]\n",
      " [  3.56300000e+01  -4.60000000e-01  -4.80000000e-01]\n",
      " [  2.06400000e+01   7.00000000e-02  -4.60000000e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Loading ColorChecker24 Lab_D50 value from X-rite data(after 2015)\n",
    "import numpy as np\n",
    "\n",
    "def parse_data_file(file_path):\n",
    "    # Deepseek\n",
    "    # 初始化存储变量\n",
    "    string_list = []\n",
    "    numeric_data = []\n",
    "    \n",
    "    # 标志是否开始/结束读取数据\n",
    "    reading_data = False\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # 去除首尾空白字符\n",
    "            \n",
    "            if not reading_data:\n",
    "                if line == 'BEGIN_DATA':\n",
    "                    reading_data = True\n",
    "                continue\n",
    "            else:\n",
    "                if line == 'END_DATA':\n",
    "                    break\n",
    "                \n",
    "                # 分割数据行\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) != 4:\n",
    "                    continue  # 跳过格式不正确的行\n",
    "                \n",
    "                # 解析数据\n",
    "                string_part = parts[0]\n",
    "                try:\n",
    "                    numeric_parts = [float(x) for x in parts[1:4]]\n",
    "                except ValueError:\n",
    "                    continue  # 跳过数值转换失败的行\n",
    "                \n",
    "                # 存储数据\n",
    "                string_list.append(string_part)\n",
    "                numeric_data.append(numeric_parts)\n",
    "    \n",
    "    # 将数值数据转换为N×3的NumPy数组\n",
    "    numeric_array = np.array(numeric_data)\n",
    "    \n",
    "    return string_list, numeric_array\n",
    "\n",
    "patch_name, lab_values = parse_data_file('RefPatches.txt')\n",
    "# The value is column first, where A* is the first column.\n",
    "patch_name_row_first = np.array(patch_name).reshape(4, 6, order='F').ravel(order='C')\n",
    "lab_values_row_first = lab_values.reshape((4, 6, 3), order='F').reshape((-1, 3), order='C')\n",
    "print(patch_name_row_first)\n",
    "print(lab_values_row_first)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77ca403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34891221  0.36417406]\n"
     ]
    }
   ],
   "source": [
    "# Transform Lab_D50 to XYZ_D50 using colour-science package\n",
    "\n",
    "XYZ_D50_values = colour.Lab_to_XYZ(lab_values_row_first, \n",
    "                                   illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']) # Lab measured in D50\n",
    "# The D50 subscript indicates that the XYZ values are obtained under the D50 illuminant.\n",
    "# print(XYZ_D50_values)\n",
    "print(colour.XYZ_to_xy(XYZ_D50_values[18])) # the brightest white patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c1e3b",
   "metadata": {},
   "source": [
    "The XYZ values could be transform to other illuminant by:\n",
    "  1. Implicitly using *Identical* matrix (NOT recommanded) for XYZ to LMS transform, then scaling under *von Kries* hypothesis.\\\n",
    "     This can be done by changing the `illuminant` parameter in `Lab_to_XYZ` function.\\\n",
    "     Also see the document and the source code of `Lab_to_XYZ` function. (https://colour.readthedocs.io/en/develop/_modules/colour/models/cie_lab.html#Lab_to_XYZ)\\\n",
    "\n",
    "  2. Explicitly using *Bradford* matrix or other matrix (such as *CAT02*) to transform.\n",
    "\n",
    "The area prefers *Bradford* method (For historical reason? maybe have a look for *CAT02* matrix), but it would be better if we can **measure the spectra** for the chart.\n",
    "\n",
    "We have generated $XYZ_{D65}$ values by all three methods below for the CC24 chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f8d614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Manually written Lab to XYZ_D50 transformation\n",
    "\n",
    "def lab_to_xyz_d50(lab_values):\n",
    "    # The basic idea is, transforming XYZ to physiologically relavent LMS space, scaling in LMS space, and then transform back.\n",
    "    # There are multiple options of matirx for XYZ to LMS, probably because of different illuminant spectra.\n",
    "    # including Identical, Bradford and Von Kries\n",
    "    # See also: \n",
    "    #   1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/bradford_e.html\n",
    "    #   2. http://www.brucelindbloom.com/index.html?Eqn_ChromAdapt.html\n",
    "    # For information about XYZ-Lab transformation, see: \n",
    "    #   1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/colorspace3_e.html\n",
    "    \n",
    "    # Using Bradford M_A matrix for XYZ-LMS conversion\n",
    "    M_A = np.array([\n",
    "        [0.8951, 0.2664, -0.1614],\n",
    "        [-0.7502, 1.7135, 0.0367],\n",
    "        [0.0389, -0.0685, 1.0296]\n",
    "    ])\n",
    "    # 定义D50white point\n",
    "    D50 = np.array([96.42, 100.0, 82.52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbc7be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White patch(0.05D):\n",
      "Identical xy: [ 0.31644451  0.33509554]\n",
      "Bradford xy: [ 0.31606103  0.33525624]\n",
      "CAT02 xy: [ 0.31598245  0.33513653]\n"
     ]
    }
   ],
   "source": [
    "# Transform XYZ (D50 illuminant) to XYZ (D65 illuminant)\n",
    "\n",
    "# Method 1. Change illuminant when Lab->XYZ (implicitly)\n",
    "XYZ_D65_values_identical = colour.Lab_to_XYZ(lab_values_row_first, illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])\n",
    "\n",
    "# Method 2. Change illuminant under XYZ using Bradford\n",
    "color_correction_mtx_bradford = colour.adaptation.matrix_chromatic_adaptation_VonKries(\n",
    "    XYZ_w=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50'])),\n",
    "    XYZ_wr=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])),\n",
    "    transform='Bradford',\n",
    ")\n",
    "# Transform from w to wr, the naming is arbitrary.\n",
    "# This produce M_{cat} = M_A^{-1} @ S @M_A, where M_A is Bradford matrix and S is scaling matrix depending on src. and dest. illuminant.\n",
    "XYZ_D65_values_bradford = XYZ_D50_values @ color_correction_mtx_bradford.T\n",
    "\n",
    "# Method 3. Change illuminant under XYZ using CAT02\n",
    "color_correction_mtx_cat02 = colour.adaptation.matrix_chromatic_adaptation_VonKries(\n",
    "    XYZ_w=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50'])),\n",
    "    XYZ_wr=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])),\n",
    "    transform='CAT02',\n",
    ")\n",
    "XYZ_D65_values_cat02 = XYZ_D50_values @ color_correction_mtx_cat02.T\n",
    "\n",
    "# print(XYZ_D65_values)\n",
    "print('White patch(0.05D):')\n",
    "print(f'Identical xy: {colour.XYZ_to_xy(XYZ_D65_values_identical[18])}')\n",
    "print(f'Bradford xy: {colour.XYZ_to_xy(XYZ_D65_values_bradford[18])}') # the brightest white patch\n",
    "print(f'CAT02 xy: {colour.XYZ_to_xy(XYZ_D65_values_cat02[18])}')\n",
    "# Here we could see the difference by using Bradford and Identical matrix in von Keris adaptation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8be6d4",
   "metadata": {},
   "source": [
    "#### a2. Observation\n",
    "For dE calculation, we need Lab values again, which requires XYZ -> Lab transformation with illuminant again.\\\n",
    "If the XYZ->Lab inverse path is not the same with the forward one, dE increases prominantly.\n",
    "\n",
    "For the three method mentioned above, we should **carefully calculate back** to Lab in order to get the accurate dE,\\\n",
    "which reflects the actual residual error introduced by the color correction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44224012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.76300704  0.78461623  2.55468098  1.27930158  2.1124803   0.36321578]\n",
      " [ 1.27623702  4.2126116   0.74909598  1.02017003  1.98745382  2.14843468]\n",
      " [ 4.65064181  1.03465616  0.78876897  2.62805336  0.48428062  2.14900997]\n",
      " [ 0.37530771  0.05705085  0.01716734  0.0189219   0.06967623  0.06471169]]\n",
      "dE max: 4.65, min: 0.02, avg: 1.32\n",
      "dE max: 0.00, min: 0.00, avg: 0.00\n",
      "dE max: 0.00, min: 0.00, avg: 0.00\n"
     ]
    }
   ],
   "source": [
    "# The illuminant transformation causes dE:\n",
    "# LabD50 -> XYZD50 -Bradford-> XYZD65 -(Implicitly Identical) -> LabD50\n",
    "dE_demo_1 = colour.delta_E(lab_values_row_first, colour.XYZ_to_Lab(XYZ_D65_values_bradford, illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])).reshape(4,6)\n",
    "print(dE_demo_1)\n",
    "print(f'dE max: {np.max(dE_demo_1):.2f}, min: {np.min(dE_demo_1):.2f}, avg: {np.mean(dE_demo_1):.2f}')\n",
    "\n",
    "# It seems like you should do all things inversely to get near 0 dE.\n",
    "dE_demo_2 = colour.delta_E(lab_values_row_first, colour.XYZ_to_Lab(XYZ_D65_values_identical, illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])).reshape(4,6)\n",
    "print(f'dE max: {np.max(dE_demo_2):.2f}, min: {np.min(dE_demo_2):.2f}, avg: {np.mean(dE_demo_2):.2f}')\n",
    "\n",
    "dE_demo_3 = colour.delta_E(lab_values_row_first, \n",
    "                           colour.XYZ_to_Lab(XYZ_D65_values_bradford @ np.linalg.inv(color_correction_mtx_bradford).T, \n",
    "                                             illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                             )\n",
    "                           ).reshape(4,6)\n",
    "print(f'dE max: {np.max(dE_demo_3):.2f}, min: {np.min(dE_demo_3):.2f}, avg: {np.mean(dE_demo_3):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0150613",
   "metadata": {},
   "source": [
    "#### b. Acquire CC24 measurements from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c78958b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define essential parameters\n",
    "\n",
    "wb_params = awb_params # (1.87217887201, 1.27358336204, 1.0, -16.2625453031, -13.099179932, 0.0) # or awb_params calculated before\n",
    "repeats = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0373f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n",
      "RAW Grabbed: img.max(): 4094, img.min(): 32\n",
      "After Debayer: img.max(): 65535, img.min(): 0\n"
     ]
    }
   ],
   "source": [
    "# Acquire preview image\n",
    "\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "\n",
    "mycam.open()\n",
    "raw_img = mycam.grab_raw()\n",
    "mycam.close()\n",
    "# img最大值最小值\n",
    "print(f'RAW Grabbed: img.max(): {raw_img.max()}, img.min(): {raw_img.min()}')\n",
    "img = raw_img - BLC\n",
    "img = raw_wb(img, \n",
    "             *wb_params, \n",
    "             pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "if BAYER_PATTERN == 'RGGB':\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BAYER_RGGB2RGB)\n",
    "elif BAYER_PATTERN == 'BGGR':\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BAYER_BGGR2RGB)\n",
    "print(f'After Debayer: img.max(): {img.max()}, img.min(): {img.min()}')\n",
    "img = img.astype(np.float32) / 65535\n",
    "plt.imshow(img)\n",
    "plt.title('White balanced and debayered linear device RGB image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c0d4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 4 corners of the chart\n",
    "chart_corners = np.array([\n",
    "    [1126, 704],\n",
    "    [1521, 704],\n",
    "    [1126, 1294],\n",
    "    [1521, 1294]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cecae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch  1: Mean RGB = ('40.74', '24.78', '17.92')\n",
      "Patch  2: Mean RGB = ('148.84', '96.26', '79.75')\n",
      "Patch  3: Mean RGB = ('56.50', '72.92', '102.88')\n",
      "Patch  4: Mean RGB = ('26.40', '30.54', '13.92')\n",
      "Patch  5: Mean RGB = ('76.85', '79.26', '117.77')\n",
      "Patch  6: Mean RGB = ('68.10', '114.91', '106.16')\n",
      "Patch  7: Mean RGB = ('158.14', '63.71', '20.94')\n",
      "Patch  8: Mean RGB = ('42.07', '59.12', '116.91')\n",
      "Patch  9: Mean RGB = ('125.74', '42.64', '44.08')\n",
      "Patch 10: Mean RGB = ('27.98', '23.60', '41.03')\n",
      "Patch 11: Mean RGB = ('84.19', '96.70', '23.27')\n",
      "Patch 12: Mean RGB = ('139.75', '75.19', '16.99')\n",
      "Patch 13: Mean RGB = ('21.13', '34.66', '81.85')\n",
      "Patch 14: Mean RGB = ('26.03', '55.88', '19.28')\n",
      "Patch 15: Mean RGB = ('88.75', '22.22', '19.14')\n",
      "Patch 16: Mean RGB = ('166.46', '111.93', '10.14')\n",
      "Patch 17: Mean RGB = ('101.83', '47.31', '75.10')\n",
      "Patch 18: Mean RGB = ('28.58', '62.25', '89.79')\n",
      "Patch 19: Mean RGB = ('253.37', '249.41', '244.78')\n",
      "Patch 20: Mean RGB = ('161.95', '162.16', '162.25')\n",
      "Patch 21: Mean RGB = ('97.86', '98.68', '99.36')\n",
      "Patch 22: Mean RGB = ('48.33', '48.35', '48.34')\n",
      "Patch 23: Mean RGB = ('20.34', '21.02', '21.29')\n",
      "Patch 24: Mean RGB = ('5.67', '6.15', '5.92')\n"
     ]
    }
   ],
   "source": [
    "# Extract 24 patches using correction_utils\n",
    "\n",
    "from correction_utils import calculate_warped_bboxes, extract_colors_warped_bbox, draw_warped_bboxes\n",
    "# 1. Calculate the warped bboxes on the original image\n",
    "# Since orientation is now locked to landscape, we use 4 rows and 6 columns.\n",
    "warped_bboxes = calculate_warped_bboxes(chart_corners, rows=4, cols=6, margin_percent=0.2)\n",
    "\n",
    "# 2. Extract mean colors directly from the original image `img`\n",
    "device_rgb_values_sample = extract_colors_warped_bbox(img, warped_bboxes)\n",
    "\n",
    "# 3. Visualize the bboxes\n",
    "# Draw the warped bboxes on the original, uncorrected image\n",
    "img_with_warped_bboxes = draw_warped_bboxes(img, warped_bboxes)\n",
    "\n",
    "# 4. Print the values\n",
    "for i, rgb in enumerate(device_rgb_values_sample):\n",
    "    rgb_255 = tuple(f'{c * 255:.2f}' for c in rgb)\n",
    "    print(f\"Patch {i+1:2d}: Mean RGB = {rgb_255}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img_with_warped_bboxes)\n",
    "plt.title(\"Warped BBoxes on Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b48959cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n"
     ]
    }
   ],
   "source": [
    "# Acquire repeat measurements\n",
    "\n",
    "from correction_utils import suppress_output\n",
    "raw_wb_slience = suppress_output(raw_wb)\n",
    "\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "mycam.open()\n",
    "\n",
    "wb_debayered_imgs = []\n",
    "for i in range(repeats):\n",
    "    raw_img = mycam.grab_raw()\n",
    "\n",
    "    # WB + Debayer\n",
    "    img = raw_img - BLC\n",
    "    img = raw_wb_slience(img, \n",
    "                *wb_params, \n",
    "                pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "    if BAYER_PATTERN == 'RGGB':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_RGGB2RGB)\n",
    "    elif BAYER_PATTERN == 'BGGR':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_BGGR2RGB)\n",
    "\n",
    "    img = img.astype(np.float32) / 65535\n",
    "\n",
    "    wb_debayered_imgs.append(img)\n",
    "mycam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00950f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or using measurements from awb run.\n",
    "from correction_utils import suppress_output\n",
    "raw_wb_slience = suppress_output(raw_wb)\n",
    "\n",
    "wb_debayered_imgs = []\n",
    "for raw_img in imgs:\n",
    "    # WB + Debayer\n",
    "    img = raw_img - BLC\n",
    "    img = raw_wb_slience(img, \n",
    "                *wb_params, \n",
    "                pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "    if BAYER_PATTERN == 'RGGB':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_RGGB2RGB)\n",
    "    elif BAYER_PATTERN == 'BGGR':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_BGGR2RGB)\n",
    "\n",
    "    img = img.astype(np.float32) / 65535\n",
    "    wb_debayered_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ede62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_rgb_values_np.shape: (100, 24, 3)\n"
     ]
    }
   ],
   "source": [
    "# Run color extraction from 24 patches\n",
    "device_rgb_values_list = []\n",
    "for img in wb_debayered_imgs:\n",
    "    device_rgb_values = extract_colors_warped_bbox(img, warped_bboxes)\n",
    "    device_rgb_values_list.append(device_rgb_values)\n",
    "device_rgb_values_np = np.array(device_rgb_values_list)\n",
    "print(f'device_rgb_values_np.shape: {device_rgb_values_np.shape}')\n",
    "device_rgb_values = np.mean(device_rgb_values_np, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33a1d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correction matrix (so called Forward Matrix in DNG glossary)\n",
    "\n",
    "fwd_mtx_identical = colour.characterisation.matrix_colour_correction_Cheung2004(device_rgb_values, XYZ_D65_values_identical)\n",
    "fwd_mtx_bradford = colour.characterisation.matrix_colour_correction_Cheung2004(device_rgb_values, XYZ_D65_values_bradford)\n",
    "fwd_mtx_cat02 = colour.characterisation.matrix_colour_correction_Cheung2004(device_rgb_values, XYZ_D65_values_cat02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57399854",
   "metadata": {},
   "source": [
    "We could evaluate the quality of colour correction matrix by calculating $dE_{00}$ between corrected and original colours.\n",
    "\n",
    "The corrected color should be carefully inversed to $Lab_{D50}$. \\\n",
    "Once the inversion is correct, the dE value should only be affected by the colour correction matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b984a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dE00_identical: \n",
      "[[ 1.91132224  3.53566835  3.24345017  0.74500562  0.62514335  1.97205114]\n",
      " [ 2.30899513  2.76655074  2.00306014  3.5179676   1.88586466  2.43833222]\n",
      " [ 4.50724413  1.69614996  2.80327743  1.18214713  4.32541145  4.1538634 ]\n",
      " [ 0.8538127   1.80441942  1.73861295  2.73804133  2.93468015  4.5865968 ]]\n",
      "  dE max: 4.59, min: 0.63, avg: 2.51\n",
      "dE00_bradford: \n",
      "[[ 1.91132224  3.53566835  3.24345017  0.74500562  0.62514335  1.97205114]\n",
      " [ 2.30899513  2.76655074  2.00306014  3.5179676   1.88586466  2.43833222]\n",
      " [ 4.50724413  1.69614996  2.80327743  1.18214713  4.32541145  4.1538634 ]\n",
      " [ 0.8538127   1.80441942  1.73861295  2.73804133  2.93468015  4.5865968 ]]\n",
      "  dE max: 4.59, min: 0.63, avg: 2.51\n",
      "dE00_cat02: \n",
      "[[ 1.91132224  3.53566835  3.24345017  0.74500562  0.62514335  1.97205114]\n",
      " [ 2.30899513  2.76655074  2.00306014  3.5179676   1.88586466  2.43833222]\n",
      " [ 4.50724413  1.69614996  2.80327743  1.18214713  4.32541145  4.1538634 ]\n",
      " [ 0.8538127   1.80441942  1.73861295  2.73804133  2.93468015  4.5865968 ]]\n",
      "  dE max: 4.59, min: 0.63, avg: 2.51\n"
     ]
    }
   ],
   "source": [
    "# Calculate dE00 of nominal values and corrected values\n",
    "\n",
    "CC24_XYZ_corrected_identical = device_rgb_values @ fwd_mtx_identical.T\n",
    "CC24_XYZ_corrected_bradford = device_rgb_values @ fwd_mtx_bradford.T\n",
    "CC24_XYZ_corrected_cat02 = device_rgb_values @ fwd_mtx_cat02.T\n",
    "\n",
    "dE00_identical = colour.delta_E(lab_values_row_first, \n",
    "                      colour.XYZ_to_Lab(CC24_XYZ_corrected_identical, \n",
    "                                        illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65']\n",
    "                                        )\n",
    "                     )\n",
    "dE00_bradford = colour.delta_E(lab_values_row_first, \n",
    "                      colour.XYZ_to_Lab(CC24_XYZ_corrected_bradford @ np.linalg.inv(color_correction_mtx_bradford).T, \n",
    "                                        illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                        )\n",
    "                     )\n",
    "dE00_cat02 = colour.delta_E(lab_values_row_first, \n",
    "                      colour.XYZ_to_Lab(CC24_XYZ_corrected_cat02 @ np.linalg.inv(color_correction_mtx_cat02).T, \n",
    "                                        illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                        )\n",
    "                     )\n",
    "\n",
    "print(f'dE00_identical: \\n{dE00_identical.reshape(4,6)}')\n",
    "print(f'  dE max: {np.max(dE00_identical):.2f}, min: {np.min(dE00_identical):.2f}, avg: {np.mean(dE00_identical):.2f}')\n",
    "print(f'dE00_bradford: \\n{dE00_bradford.reshape(4,6)}')\n",
    "print(f'  dE max: {np.max(dE00_bradford):.2f}, min: {np.min(dE00_bradford):.2f}, avg: {np.mean(dE00_bradford):.2f}')\n",
    "print(f'dE00_cat02: \\n{dE00_cat02.reshape(4,6)}')\n",
    "print(f'  dE max: {np.max(dE00_cat02):.2f}, min: {np.min(dE00_cat02):.2f}, avg: {np.mean(dE00_cat02):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9db5f037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct inversion of Bradford to Lab at D65:\n",
      "  dE max: 5.81, min: 1.19, avg: 2.88\n",
      "Direct inversion of CAT02 to Lab at D65:\n",
      "  dE max: 5.74, min: 1.17, avg: 2.83\n"
     ]
    }
   ],
   "source": [
    "# If the Lab value is not perfectly inverse, it may can reflect the actual performance\n",
    "dE00_bradford_direct_lab = colour.delta_E(lab_values_row_first, \n",
    "                             colour.XYZ_to_Lab(CC24_XYZ_corrected_bradford, \n",
    "                               illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65']\n",
    "                               )\n",
    "                             )\n",
    "dE00_cat02_direct_lab = colour.delta_E(lab_values_row_first, \n",
    "                             colour.XYZ_to_Lab(CC24_XYZ_corrected_cat02, \n",
    "                               illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65']\n",
    "                               )\n",
    "                             )\n",
    "print('Direct inversion of Bradford to Lab at D65:')\n",
    "print(f'  dE max: {np.max(dE00_bradford_direct_lab):.2f}, min: {np.min(dE00_bradford_direct_lab):.2f}, avg: {np.mean(dE00_bradford_direct_lab):.2f}')\n",
    "print('Direct inversion of CAT02 to Lab at D65:')\n",
    "print(f'  dE max: {np.max(dE00_cat02_direct_lab):.2f}, min: {np.min(dE00_cat02_direct_lab):.2f}, avg: {np.mean(dE00_cat02_direct_lab):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc2bd8",
   "metadata": {},
   "source": [
    "But the sRGB value **will** be affected by different chromatic adaptation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c412025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 118   83   66  120   83   66]\n",
      " [ 210  154  137  213  154  137]\n",
      " [  99  128  163   91  129  163]\n",
      " [  89  107   60   92  106   61]\n",
      " [ 128  125  173  122  126  172]\n",
      " [ 105  183  167  103  183  167]\n",
      " [ 231  129   45  236  129   45]\n",
      " [  60   93  174   25   95  173]\n",
      " [ 205   73   97  208   74   96]\n",
      " [  83   59  106   79   60  106]\n",
      " [ 158  189   75  166  188   77]\n",
      " [ 216  154   39  222  153   41]\n",
      " [ -23   57  148 -120   60  148]\n",
      " [  71  150   75   79  149   77]\n",
      " [ 179   38   56  182   39   55]\n",
      " [ 231  196  -27  240  195  -13]\n",
      " [ 177   68  135  176   70  135]\n",
      " [ -16  123  155  -89  124  155]\n",
      " [ 241  243  237  242  243  237]\n",
      " [ 197  200  197  197  200  197]\n",
      " [ 156  160  158  156  160  158]\n",
      " [ 113  115  113  113  115  114]\n",
      " [  74   77   76   74   77   77]\n",
      " [  37   42   40   37   42   40]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate sRGB value in 8bit using different adaptation transforms\n",
    "CC24_sRGB_corrected_identical = colour.XYZ_to_sRGB(CC24_XYZ_corrected_identical)\n",
    "CC24_sRGB_corrected_bradford = colour.XYZ_to_sRGB(CC24_XYZ_corrected_bradford)\n",
    "\n",
    "print(np.hstack(((CC24_sRGB_corrected_bradford * 255).astype(int), \n",
    "      (CC24_sRGB_corrected_identical * 255).astype(int)))\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1ded6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.14944240805..1.12595000329].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.73510751741..1.09827472641].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.72443898785..1.09761140957].\n"
     ]
    }
   ],
   "source": [
    "# Validate correction by performing a forward transformation to sRGB\n",
    "img_XYZ_corrected_identical = img @ fwd_mtx_identical.T\n",
    "img_XYZ_corrected_bradford = img @ fwd_mtx_bradford.T\n",
    "img_XYZ_corrected_cat02 = img @ fwd_mtx_cat02.T\n",
    "\n",
    "img_sRGB_identical = colour.XYZ_to_sRGB(img_XYZ_corrected_identical, chromatic_adaptation_transform='Bradford', apply_cctf_encoding=True)\n",
    "img_sRGB_bradford = colour.XYZ_to_sRGB(img_XYZ_corrected_bradford, chromatic_adaptation_transform='Bradford', apply_cctf_encoding=True)\n",
    "img_sRGB_cat02 = colour.XYZ_to_sRGB(img_XYZ_corrected_cat02, chromatic_adaptation_transform='Bradford', apply_cctf_encoding=True)\n",
    "# The chromatic_adaptation_transform should not affect anything since the sRGB is D65 based.\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image (linear, device RGB)')\n",
    "ax1.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax1.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax2.imshow(img_sRGB_identical)\n",
    "ax2.set_title('Corrected Image (Implicit Identical)')\n",
    "ax2.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax2.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax3.imshow(img_sRGB_bradford)\n",
    "ax3.set_title('Corrected Image (Bradford)')\n",
    "ax3.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax3.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax4.imshow(img_sRGB_cat02)\n",
    "ax4.set_title('Corrected Image (CAT02)')\n",
    "ax4.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax4.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5e877",
   "metadata": {},
   "source": [
    "#### b2. Conclusion\n",
    "Visually, the CAT02 method is the best.\n",
    "\n",
    "We visualize the whole process of RAW development here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b84a01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative efficient calculation (using CAT02 as example) showing the whole process:\n",
    "\n",
    "from correction_utils import linear_to_srgb\n",
    "\n",
    "device_RGB_to_linear_sRGB = colour.RGB_COLOURSPACES['sRGB'].matrix_XYZ_to_RGB @ fwd_mtx_cat02\n",
    "img_sRGB_cat02_linear = np.clip(img @ device_RGB_to_linear_sRGB.T, 0, 1)\n",
    "img_sRGB_cat02 = linear_to_srgb(img_sRGB_cat02_linear)\n",
    "\n",
    "fig, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(2, 4, figsize=(16, 10))\n",
    "ax1.imshow(raw_img)\n",
    "ax1.set_title(\"RAW Image\")\n",
    "ax1.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax1.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax2.imshow(img)\n",
    "ax2.set_title(\"WB+Debayered Image (Linear)\")\n",
    "ax2.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax2.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax3.imshow(img_sRGB_cat02_linear)\n",
    "ax3.set_title(\"CAT02+Cheung2004 Fwd Corr. Img. (Linear)\")\n",
    "ax3.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax3.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax4.imshow(img_sRGB_cat02)\n",
    "ax4.set_title(\"CAT02+Cheung2004 Fwd Corr. Img. (sRGB)\")\n",
    "ax4.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax4.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax5.imshow(cv2.cvtColor(raw_img, cv2.COLOR_BAYER_RG2RGB)/4096)\n",
    "ax5.set_title('Debayer Only (Device RGB)')\n",
    "ax5.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax5.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax6.imshow(linear_to_srgb(img))\n",
    "ax6.set_title('WB+Debayered in sRGB gamma')\n",
    "ax6.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax6.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6b7f7",
   "metadata": {},
   "source": [
    "#### b3. Optimize calculation process to accelerate the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e4a2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe a C extension.\n",
    "# Implemented 250731 13ms/2448x2048@12bit, uint16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44548b9c",
   "metadata": {},
   "source": [
    "#### c. Using customized loss function (dE2000 based) to calculate forward matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b7e6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  100, Loss (dE2000**3): 19.9681\n",
      "Iteration  200, Loss (dE2000**3): 19.2230\n",
      "Iteration  300, Loss (dE2000**3): 19.0495\n",
      "Iteration  400, Loss (dE2000**3): 19.0390\n",
      "Iteration  500, Loss (dE2000**3): 19.0228\n",
      "Iteration  600, Loss (dE2000**3): 18.8168\n",
      "Iteration  700, Loss (dE2000**3): 18.7198\n",
      "Iteration  800, Loss (dE2000**3): 18.7105\n",
      "Iteration  900, Loss (dE2000**3): 18.7082\n",
      "Iteration 1000, Loss (dE2000**3): 18.7082\n",
      "\n",
      "Optimization finished.\n",
      "Final Loss (dE2000**3): 18.7082\n"
     ]
    }
   ],
   "source": [
    "# A good initial value is essential for better dE.\n",
    "\n",
    "sigma_init = 0.01\n",
    "\n",
    "from correction_utils import forward_matrix_slover\n",
    "\n",
    "fwd_mtx_custom_solver, final_loss = forward_matrix_slover(device_rgb_values, XYZ_D50_values, \n",
    "                                                   illuminant='D50',\n",
    "                                                   initial_matrix=fwd_mtx_cat02+np.random.normal(0, sigma_init, size=(3,3)),\n",
    "                                                   extra_illuminant_transform_XYZ=np.linalg.inv(color_correction_mtx_cat02),\n",
    "                                                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30a1b2",
   "metadata": {},
   "source": [
    "#### d. Compare the results and choose which one to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1cdc279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom forward_matrix: \n",
      "[[ 0.53777609  0.39176303 -0.07823343]\n",
      " [ 0.15362751  1.06443876 -0.31712604]\n",
      " [-0.09106248  0.23445596  0.81987655]]\n",
      "fwd_mtx by colour-science: \n",
      "[[ 0.48400457  0.49366056 -0.12875313]\n",
      " [ 0.11755779  1.14741225 -0.35974064]\n",
      " [-0.10007283  0.26020384  0.80710571]]\n",
      "dE00 from custom forward matrix:\n",
      "[ 1.74179363  3.89205456  3.57741507  1.29240565  1.25222719  1.87653517\n",
      "  2.48320028  2.0703755   2.68013947  2.28412688  2.19893733  2.49734834\n",
      "  2.36746242  0.9990171   2.18582551  1.46885639  2.89822994  4.21043201\n",
      "  0.98819987  0.87282769  1.15580178  2.43619591  2.6476921   4.37289933]\n",
      "  dE max: 4.37, min: 0.87, avg: 2.27\n",
      "dE00 from CAT02:\n",
      "[ 2.24446063  3.33668851  4.44900076  1.8306594   1.89308657  2.06439773\n",
      "  2.33215484  2.66527507  2.10619767  2.08273177  3.30988122  3.72550504\n",
      "  2.44595691  1.47184807  3.37156307  3.29109667  4.39005257  5.73675453\n",
      "  1.16693104  1.90675781  1.76869839  2.78378092  2.92742359  4.62938848]\n",
      "  dE max: 5.74, min: 1.17, avg: 2.83\n"
     ]
    }
   ],
   "source": [
    "# Print and render results\n",
    "print('custom forward_matrix: ')\n",
    "print(fwd_mtx_custom_solver)\n",
    "\n",
    "print('fwd_mtx by colour-science: ')\n",
    "print(fwd_mtx_cat02)\n",
    "\n",
    "CC24_XYZ_corrected_custom_fwd = device_rgb_values @ fwd_mtx_custom_solver.T\n",
    "\n",
    "dE00_custom_fwd_direct_lab = colour.delta_E(lab_values_row_first, \n",
    "                               colour.XYZ_to_Lab(CC24_XYZ_corrected_custom_fwd @ np.linalg.inv(color_correction_mtx_cat02).T, \n",
    "                                 illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                 )\n",
    "                               )\n",
    "\n",
    "print('dE00 from custom forward matrix:')\n",
    "print(dE00_custom_fwd_direct_lab)\n",
    "print(f'  dE max: {np.max(dE00_custom_fwd_direct_lab):.2f}, min: {np.min(dE00_custom_fwd_direct_lab):.2f}, avg: {np.mean(dE00_custom_fwd_direct_lab):.2f}')\n",
    "print('dE00 from CAT02:')\n",
    "print(dE00_cat02_direct_lab)\n",
    "print(f'  dE max: {np.max(dE00_cat02_direct_lab):.2f}, min: {np.min(dE00_cat02_direct_lab):.2f}, avg: {np.mean(dE00_cat02_direct_lab):.2f}')\n",
    "\n",
    "img_sRGB_custom_fwd = linear_to_srgb(np.clip(img @ fwd_mtx_custom_solver.T @ colour.RGB_COLOURSPACES['sRGB'].matrix_XYZ_to_RGB.T, 0, 1))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(img_sRGB_custom_fwd)\n",
    "ax1.set_title(\"Custom Forward Matrix\")\n",
    "ax1.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax1.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax1.axis('off')\n",
    "ax2.imshow(img_sRGB_cat02)\n",
    "ax2.set_title(\"CAT02 Forward Matrix\")\n",
    "ax2.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax2.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e92359c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bases of the device RGB space in XYZ color model.\n",
    "\n",
    "# Note on linear algebra: the conversion matrix which map points from space A to B, \n",
    "# literally equals to horizontal stacks of bases of space A in the coordinates of space B.\n",
    "# (Here, we assume all vectors are vertically arranged.)\n",
    "\n",
    "fig, ax = colour.plotting.plot_RGB_colourspaces_gamuts('sRGB', 'CIE XYZ')\n",
    "ax.scatter(fwd_mtx_custom_solver[:, 0], fwd_mtx_custom_solver[:, 1], fwd_mtx_custom_solver[:, 2], c = ('red', 'green', 'blue'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a574748",
   "metadata": {},
   "source": [
    "#### e. Choose and save correction results in numpy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62a23c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLC': 32, 'ADC_MAX_LEVEL': 4095, 'wb_params': (1.8538751110194334, 1.2618050211142049, 1.0, -14.453442776099127, -11.818613731445266, 0.0), 'fwd_mtx': array([[ 0.48400457,  0.49366056, -0.12875313],\n",
      "       [ 0.11755779,  1.14741225, -0.35974064],\n",
      "       [-0.10007283,  0.26020384,  0.80710571]]), 'Notes': 'D50 15% power, vertical illuminant, 10ms exposure, Analog Gain 1.0, 8mm Lens, IMX264, 5MP'}\n"
     ]
    }
   ],
   "source": [
    "# Save tag: BLC, ADC_MAX_LEVEL, wb_params, fwd_mtx and Notes\n",
    "\n",
    "Notes = 'D50 15% power, vertical illuminant, 10ms exposure, Analog Gain 1.0, 8mm Lens, IMX264, 5MP'\n",
    "mtx_to_save = fwd_mtx_cat02\n",
    "filename = 'correction_results_D65_250731.npy'\n",
    "\n",
    "np.save(filename, {'BLC': BLC, 'ADC_MAX_LEVEL': ADC_MAX_LEVEL,\n",
    "                                   'wb_params': wb_params, 'fwd_mtx': mtx_to_save, \n",
    "                                   'Notes': Notes\n",
    "                                   })\n",
    "\n",
    "# Read back and check\n",
    "data = np.load(filename, allow_pickle=True).item()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c123773",
   "metadata": {},
   "source": [
    "`wb_params`: (R_gain, G_gain, B_gain, R_dBLC, G_dBLC, B_dBLC)\n",
    "\n",
    "`fwd_mtx`: Transform from device RGB to $XYZ$ in given illuminant (e.g. D50). \n",
    "The user should calculate chromatic (illuminant) adaptation and $XYZ$->sRGB itself.\n",
    "如果已经wb，是否还需要改变fwd_mtx? 可能有微调。测试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5b18ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.8538751110194334, 1.2618050211142049, 1.0, -14.453442776099127, -11.818613731445266, 0.0)\n",
      "(1.6232238624261359, 1.3050488646488514, 1.0, -6.6773836516730469, -8.8718066707359053, 0.0)\n",
      "[[ 0.48400457  0.49366056 -0.12875313]\n",
      " [ 0.11755779  1.14741225 -0.35974064]\n",
      " [-0.10007283  0.26020384  0.80710571]]\n",
      "[[ 0.51162398  0.57441403 -0.13854522]\n",
      " [ 0.15561742  1.30252441 -0.44838334]\n",
      " [-0.09894102  0.17512108  1.0111746 ]]\n"
     ]
    }
   ],
   "source": [
    "data1 = np.load('correction_results_D65_250731.npy', allow_pickle=True).item()\n",
    "data2 = np.load('correction_results_D50_250731.npy', allow_pickle=True).item()\n",
    "print(data1['wb_params'])\n",
    "print(data2['wb_params'])\n",
    "print(data1['fwd_mtx'])\n",
    "print(data2['fwd_mtx'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
