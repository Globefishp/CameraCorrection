{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c6ae2b",
   "metadata": {},
   "source": [
    "## Calculate Raw image correction paramters\n",
    "*Author: Haiyun Huang 2025 with Deepseek*\n",
    "\n",
    "This document aims to acquire mathmatically accurate correction parameters for raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "003d3fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4230b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mvsdk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from huateng_camera_v2_tc_raw import Camera\n",
    "from raw_processing import raw_awb, raw_wb\n",
    "from correction_utils import suppress_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "24f40857",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPOSURE_TIME = 10 # ms\n",
    "ADC_MAX_LEVEL = 2**12 - 1 # No greater than 65535"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb0289",
   "metadata": {},
   "source": [
    "### 01. Acquiring AWB Correction Parameters\n",
    "The WB process will do:\n",
    "- (optional) extra dBLC, \n",
    "- clipping to per channel max level, \n",
    "- scales the RAW channels to 16bit.\n",
    "\n",
    "Acquiring params including:\n",
    "- (optional) RGB dBLC (after BLC), \n",
    "- RGB gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "716ad2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n",
      "RAW Grabbed: img.max(): 4094, img.min(): 32\n"
     ]
    }
   ],
   "source": [
    "# Acquire preview image\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "\n",
    "mycam.open()\n",
    "raw_img = mycam.grab_raw()\n",
    "mycam.close()\n",
    "# img最大值最小值\n",
    "print(f'RAW Grabbed: img.max(): {raw_img[2:, :].max()}, img.min(): {raw_img[2:, :].min()}')\n",
    "plt.imshow(raw_img)\n",
    "plt.title('RAW Preview')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f517e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting essential params for acquiring correction params\n",
    "repeats = 100\n",
    "BLC = 32\n",
    "BAYER_PATTERN = 'BGGR'\n",
    "\n",
    "# 白平衡\n",
    "# 定义两个ROI用于自动白平衡\n",
    "# ROI 1 (亮区)\n",
    "x_slice_1 = slice(1420, 1480)\n",
    "y_slice_1 = slice(940, 980)\n",
    "awb_roi_1 = (y_slice_1, x_slice_1) # y,x\n",
    "\n",
    "# ROI 2 (暗区)\n",
    "x_slice_2 = slice(1420, 1480)\n",
    "y_slice_2 = slice(1140, 1180)\n",
    "awb_roi_2 = (y_slice_2, x_slice_2) # y,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d3a37c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n"
     ]
    }
   ],
   "source": [
    "# Acquire images\n",
    "\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "mycam.open()\n",
    "\n",
    "imgs = []\n",
    "for i in range(repeats):\n",
    "    img = mycam.grab_raw()\n",
    "    imgs.append(img)\n",
    "mycam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dad86ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AWB params: (mean ± SE)\n",
      "R gain: 1.6788 ± 0.0004\n",
      "G gain: 1.3177 ± 0.0002\n",
      "B gain: 1.0000 ± 0.0000\n",
      "R dBLC: 6.4111 ± 0.2047\n",
      "G dBLC: -3.5191 ± 0.2078\n",
      "B dBLC: 0.0000 ± 0.0000\n",
      "Copy format: (1.67879033619, 1.31773854048, 1.0, 6.41108534524, -3.5191075359, 0.0)\n",
      "Parameters saved in variable `awb_params`\n"
     ]
    }
   ],
   "source": [
    "# Calculate avg. correction parameters\n",
    "raw_awb_slience = suppress_output(raw_awb)\n",
    "\n",
    "awb_params_list = []\n",
    "for img in imgs:\n",
    "    # basic BLC\n",
    "    img_BLC = img - BLC\n",
    "    # AWB\n",
    "    _, awb_params = raw_awb_slience(img_BLC, awb_roi_1, awb_roi_2, pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "    awb_params_list.append(awb_params)\n",
    "awb_params_np = np.array(awb_params_list)\n",
    "awb_params_avg = np.mean(awb_params_np, axis=0)\n",
    "awb_params_se = np.std(awb_params_np, ddof=1, axis=0)/np.sqrt(repeats)\n",
    "\n",
    "print('Average AWB params: (mean ± SE)')\n",
    "print(f'R gain: {awb_params_avg[0]:.4f} ± {awb_params_se[0]:.4f}')\n",
    "print(f'G gain: {awb_params_avg[1]:.4f} ± {awb_params_se[1]:.4f}')\n",
    "print(f'B gain: {awb_params_avg[2]:.4f} ± {awb_params_se[2]:.4f}')\n",
    "print(f'R dBLC: {awb_params_avg[3]:.4f} ± {awb_params_se[3]:.4f}')\n",
    "print(f'G dBLC: {awb_params_avg[4]:.4f} ± {awb_params_se[4]:.4f}')\n",
    "print(f'B dBLC: {awb_params_avg[5]:.4f} ± {awb_params_se[5]:.4f}')\n",
    "print(f'Copy format: ({', '.join(map(str, awb_params_avg))})')\n",
    "awb_params = tuple(awb_params_avg)\n",
    "print('Parameters saved in variable `awb_params`')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d19fc",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "D65 Room LED Light\n",
    "> Average AWB params: (mean ± SE)\\\n",
    "`R gain`: 1.8722 ± 0.0005\\\n",
    "`G gain`: 1.2736 ± 0.0002\\\n",
    "`B gain`: 1.0000 ± 0.0000\\\n",
    "`R dBLC`: -16.2625 ± 0.2017\\\n",
    "`G dBLC`: -13.0992 ± 0.2143\\\n",
    "`B dBLC`: 0.0000 ± 0.0000\\\n",
    "Copy format: `(1.87217887201, 1.27358336204, 1.0, -16.2625453031, -13.099179932, 0.0)`\n",
    "\n",
    "D50 Sunlike Light (10ms exposure, white patch ~ 3000-4000 DN @ 12bit)\n",
    "> Average AWB params: (mean ± SE)\\\n",
    "`R gain`: 1.6223 ± 0.0003\\\n",
    "`G gain`: 1.3053 ± 0.0002\\\n",
    "`B gain`: 1.0000 ± 0.0000\\\n",
    "`R dBLC`: -5.5832 ± 0.1601\\\n",
    "`G dBLC`: -6.5196 ± 0.1868\\\n",
    "`B dBLC`: 0.0000 ± 0.0000\\\n",
    "Copy format: `(1.62229078895, 1.30534488103, 1.0, -5.58319935118, -6.51955880128, 0.0)`\\\n",
    "Parameters saved in variable `awb_params`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8a97f",
   "metadata": {},
   "source": [
    "### 02. Calculate Forward Matrix\n",
    "Transform colors from device $RGB$ to $XYZ_{D50}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b84986",
   "metadata": {},
   "source": [
    "#### a1. Preparing ColorChecker24 Reference Data\n",
    "Convert reference $Lab_{D50}$ data to $XYZ$ for given illuminant by *Bradford* + *von Keris* method.\n",
    "\n",
    "The reference ColorChecker24 patches are measured under D50 illuminant in $Lab_{D50}$ format\\\n",
    "We need to transform such refernece $Lab$ value to $XYZ$ space under the constraint of D50 illuminant.\n",
    "\n",
    "The layout of CC24: 4 rows, 6 columns. `A1` is at upper left, `F4` is at lower right.\n",
    "\n",
    "多解释一些：\n",
    "1. 对于反射式测试卡，反射率是其本质，而对于传感器，光谱辐照是其本质。\n",
    "2. D50照明定义了照明谱，只有在给定照明谱的情况下，才能拿到光谱辐照，拿到加色性的XYZ值。\n",
    "3. 这也是为什么测试卡用Lab标注值，而不是XYZ，因为XYZ会随着照明不同而改变。但Lab是归一化到白点（*相对*稳定，此为von Kries假设下的方法），并且定义了测量白点是D50（Lab空间需要给定白点才在辐照水平有意义）。\n",
    "4. $XYZ_{D50}$的下标并没有实际意义，因为XYZ空间不依赖白点而存在，只是为了表示是D50照明下获得的值。\n",
    "5. 对于不同白点的转换，常用Bradford比色法，主要是将XYZ值转移到LMS空间后缩放。不同比色法定义的这个转移矩阵$M_A$不同。\n",
    "6. 对于更精确的应用，应当直接从各色块的反射率曲线推导给定光源（如D65）下的XYZ值，而不是用$Lab_{D50}$通过Bradford。 参见：https://babelcolor.com/colorchecker-2.htm#xl_CCP2_images\n",
    "7. 由于新版ColorChecker24没有平均的反射率曲线可用，本文档推荐使用Bradford比色法处理照明非D50的情况。\n",
    "\n",
    "The basic idea is, transforming $XYZ$ to physiologically relavent $LMS$ space, scaling in $LMS$ space (based on *von Kries* hypothesis), and then transform back.\\\n",
    "There are multiple options of matirx for $XYZ$ to $LMS$, probably because of different illuminant spectra,\\\n",
    "including *Identical*, *Bradford* methods, etc.\\\n",
    "See documents of `colour.adaptation.CAT_*` for more methods based on *von Kries* hypothesis.\n",
    "\n",
    "See more mathmatical details:\n",
    "  1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/bradford_e.html\\\n",
    "  2. http://www.brucelindbloom.com/index.html?Eqn_ChromAdapt.html\\\n",
    "\n",
    "For information about XYZ-Lab transformation, see: \n",
    "  1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/colorspace3_e.html\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43292044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the illuminant of the calibration images, CIE 1931 XYZ value.\n",
    "\n",
    "import colour\n",
    "\n",
    "illuminant = colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9d75b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1' 'B1' 'C1' 'D1' 'E1' 'F1' 'A2' 'B2' 'C2' 'D2' 'E2' 'F2' 'A3' 'B3' 'C3'\n",
      " 'D3' 'E3' 'F3' 'A4' 'B4' 'C4' 'D4' 'E4' 'F4']\n",
      "[[  3.75400000e+01   1.43700000e+01   1.49200000e+01]\n",
      " [  6.46600000e+01   1.92700000e+01   1.75000000e+01]\n",
      " [  4.93200000e+01  -3.82000000e+00  -2.25400000e+01]\n",
      " [  4.34600000e+01  -1.27400000e+01   2.27200000e+01]\n",
      " [  5.49400000e+01   9.61000000e+00  -2.47900000e+01]\n",
      " [  7.04800000e+01  -3.22600000e+01  -3.70000000e-01]\n",
      " [  6.27300000e+01   3.58300000e+01   5.65000000e+01]\n",
      " [  3.94300000e+01   1.07500000e+01  -4.51700000e+01]\n",
      " [  5.05700000e+01   4.86400000e+01   1.66700000e+01]\n",
      " [  3.01000000e+01   2.25400000e+01  -2.08700000e+01]\n",
      " [  7.17700000e+01  -2.41300000e+01   5.81900000e+01]\n",
      " [  7.15100000e+01   1.82400000e+01   6.73700000e+01]\n",
      " [  2.83700000e+01   1.54200000e+01  -4.98000000e+01]\n",
      " [  5.43800000e+01  -3.97200000e+01   3.22700000e+01]\n",
      " [  4.24300000e+01   5.10500000e+01   2.86200000e+01]\n",
      " [  8.18000000e+01   2.67000000e+00   8.04100000e+01]\n",
      " [  5.06300000e+01   5.12800000e+01  -1.41200000e+01]\n",
      " [  4.95700000e+01  -2.97100000e+01  -2.83200000e+01]\n",
      " [  9.51900000e+01  -1.03000000e+00   2.93000000e+00]\n",
      " [  8.12900000e+01  -5.70000000e-01   4.40000000e-01]\n",
      " [  6.68900000e+01  -7.50000000e-01  -6.00000000e-02]\n",
      " [  5.07600000e+01  -1.30000000e-01   1.40000000e-01]\n",
      " [  3.56300000e+01  -4.60000000e-01  -4.80000000e-01]\n",
      " [  2.06400000e+01   7.00000000e-02  -4.60000000e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Loading ColorChecker24 Lab_D50 value from X-rite data(after 2015)\n",
    "import numpy as np\n",
    "\n",
    "def parse_data_file(file_path):\n",
    "    # Deepseek\n",
    "    # 初始化存储变量\n",
    "    string_list = []\n",
    "    numeric_data = []\n",
    "    \n",
    "    # 标志是否开始/结束读取数据\n",
    "    reading_data = False\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # 去除首尾空白字符\n",
    "            \n",
    "            if not reading_data:\n",
    "                if line == 'BEGIN_DATA':\n",
    "                    reading_data = True\n",
    "                continue\n",
    "            else:\n",
    "                if line == 'END_DATA':\n",
    "                    break\n",
    "                \n",
    "                # 分割数据行\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) != 4:\n",
    "                    continue  # 跳过格式不正确的行\n",
    "                \n",
    "                # 解析数据\n",
    "                string_part = parts[0]\n",
    "                try:\n",
    "                    numeric_parts = [float(x) for x in parts[1:4]]\n",
    "                except ValueError:\n",
    "                    continue  # 跳过数值转换失败的行\n",
    "                \n",
    "                # 存储数据\n",
    "                string_list.append(string_part)\n",
    "                numeric_data.append(numeric_parts)\n",
    "    \n",
    "    # 将数值数据转换为N×3的NumPy数组\n",
    "    numeric_array = np.array(numeric_data)\n",
    "    \n",
    "    return string_list, numeric_array\n",
    "\n",
    "patch_name, lab_values = parse_data_file('RefPatches.txt')\n",
    "# The value is column first, where A* is the first column.\n",
    "patch_name_row_first = np.array(patch_name).reshape(4, 6, order='F').ravel(order='C')\n",
    "lab_values_row_first = lab_values.reshape((4, 6, 3), order='F').reshape((-1, 3), order='C')\n",
    "print(patch_name_row_first)\n",
    "print(lab_values_row_first)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "77ca403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34891221  0.36417406]\n"
     ]
    }
   ],
   "source": [
    "# Transform Lab_D50 to XYZ_D50 using colour-science package\n",
    "\n",
    "XYZ_D50_values = colour.Lab_to_XYZ(lab_values_row_first, \n",
    "                                   illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']) # Lab measured in D50\n",
    "# The D50 subscript indicates that the XYZ values are obtained under the D50 illuminant.\n",
    "# print(XYZ_D50_values)\n",
    "print(colour.XYZ_to_xy(XYZ_D50_values[18])) # the brightest white patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c1e3b",
   "metadata": {},
   "source": [
    "The XYZ values could be transform to other illuminant by:\n",
    "  1. Implicitly using *Identical* matrix (NOT recommanded) for XYZ to LMS transform, then scaling under *von Kries* hypothesis.\\\n",
    "     This can be done by changing the `illuminant` parameter in `Lab_to_XYZ` function.\\\n",
    "     Also see the document and the source code of `Lab_to_XYZ` function. (https://colour.readthedocs.io/en/develop/_modules/colour/models/cie_lab.html#Lab_to_XYZ)\\\n",
    "\n",
    "  2. Explicitly using *Bradford* matrix or other matrix (such as *CAT02*) to transform.\n",
    "\n",
    "The area prefers *Bradford* method (For historical reason? maybe have a look for *CAT02* matrix), but it would be better if we can **measure the spectra** for the chart.\n",
    "\n",
    "We have generated $XYZ_{D65}$ values by all three methods below for the CC24 chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1f8d614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Manually written Lab to XYZ_D50 transformation\n",
    "\n",
    "def lab_to_xyz_d50(lab_values):\n",
    "    # The basic idea is, transforming XYZ to physiologically relavent LMS space, scaling in LMS space, and then transform back.\n",
    "    # There are multiple options of matirx for XYZ to LMS, probably because of different illuminant spectra.\n",
    "    # including Identical, Bradford and Von Kries\n",
    "    # See also: \n",
    "    #   1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/bradford_e.html\n",
    "    #   2. http://www.brucelindbloom.com/index.html?Eqn_ChromAdapt.html\n",
    "    # For information about XYZ-Lab transformation, see: \n",
    "    #   1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/colorspace3_e.html\n",
    "    \n",
    "    # Using Bradford M_A matrix for XYZ-LMS conversion\n",
    "    M_A = np.array([\n",
    "        [0.8951, 0.2664, -0.1614],\n",
    "        [-0.7502, 1.7135, 0.0367],\n",
    "        [0.0389, -0.0685, 1.0296]\n",
    "    ])\n",
    "    # 定义D50white point\n",
    "    D50 = np.array([96.42, 100.0, 82.52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9fbc7be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White patch(0.05D):\n",
      "Identical xy: [ 0.31644451  0.33509554]\n",
      "Bradford xy: [ 0.31606103  0.33525624]\n",
      "CAT02 xy: [ 0.31598245  0.33513653]\n"
     ]
    }
   ],
   "source": [
    "# Transform XYZ (D50 illuminant) to XYZ (D65 illuminant)\n",
    "\n",
    "# Method 1. Change illuminant when Lab->XYZ (implicitly)\n",
    "XYZ_D65_values_identical = colour.Lab_to_XYZ(lab_values_row_first, illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])\n",
    "\n",
    "# Method 2. Change illuminant under XYZ using Bradford\n",
    "color_correction_mtx_bradford = colour.adaptation.matrix_chromatic_adaptation_VonKries(\n",
    "    XYZ_w=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50'])),\n",
    "    XYZ_wr=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])),\n",
    "    transform='Bradford',\n",
    ")\n",
    "# Transform from w to wr, the naming is arbitrary.\n",
    "# This produce M_{cat} = M_A^{-1} @ S @M_A, where M_A is Bradford matrix and S is scaling matrix depending on src. and dest. illuminant.\n",
    "XYZ_D65_values_bradford = XYZ_D50_values @ color_correction_mtx_bradford.T\n",
    "\n",
    "# Method 3. Change illuminant under XYZ using CAT02\n",
    "color_correction_mtx_cat02 = colour.adaptation.matrix_chromatic_adaptation_VonKries(\n",
    "    XYZ_w=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50'])),\n",
    "    XYZ_wr=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])),\n",
    "    transform='CAT02',\n",
    ")\n",
    "XYZ_D65_values_cat02 = XYZ_D50_values @ color_correction_mtx_cat02.T\n",
    "\n",
    "# print(XYZ_D65_values)\n",
    "print('White patch(0.05D):')\n",
    "print(f'Identical xy: {colour.XYZ_to_xy(XYZ_D65_values_identical[18])}')\n",
    "print(f'Bradford xy: {colour.XYZ_to_xy(XYZ_D65_values_bradford[18])}') # the brightest white patch\n",
    "print(f'CAT02 xy: {colour.XYZ_to_xy(XYZ_D65_values_cat02[18])}')\n",
    "# Here we could see the difference by using Bradford and Identical matrix in von Keris adaptation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8be6d4",
   "metadata": {},
   "source": [
    "#### a2. Observation\n",
    "For dE calculation, we need Lab values again, which requires XYZ -> Lab transformation with illuminant again.\\\n",
    "If the XYZ->Lab inverse path is not the same with the forward one, dE increases prominantly.\n",
    "\n",
    "For the three method mentioned above, we should **carefully calculate back** to Lab in order to get the accurate dE,\\\n",
    "which reflects the actual residual error introduced by the color correction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "44224012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.76300704  0.78461623  2.55468098  1.27930158  2.1124803   0.36321578]\n",
      " [ 1.27623702  4.2126116   0.74909598  1.02017003  1.98745382  2.14843468]\n",
      " [ 4.65064181  1.03465616  0.78876897  2.62805336  0.48428062  2.14900997]\n",
      " [ 0.37530771  0.05705085  0.01716734  0.0189219   0.06967623  0.06471169]]\n",
      "dE max: 4.65, min: 0.02, avg: 1.32\n",
      "dE max: 0.00, min: 0.00, avg: 0.00\n",
      "dE max: 0.00, min: 0.00, avg: 0.00\n"
     ]
    }
   ],
   "source": [
    "# The illuminant transformation causes dE:\n",
    "# LabD50 -> XYZD50 -Bradford-> XYZD65 -(Implicitly Identical) -> LabD50\n",
    "dE_demo_1 = colour.delta_E(lab_values_row_first, colour.XYZ_to_Lab(XYZ_D65_values_bradford, illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])).reshape(4,6)\n",
    "print(dE_demo_1)\n",
    "print(f'dE max: {np.max(dE_demo_1):.2f}, min: {np.min(dE_demo_1):.2f}, avg: {np.mean(dE_demo_1):.2f}')\n",
    "\n",
    "# It seems like you should do all things inversely to get near 0 dE.\n",
    "dE_demo_2 = colour.delta_E(lab_values_row_first, colour.XYZ_to_Lab(XYZ_D65_values_identical, illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])).reshape(4,6)\n",
    "print(f'dE max: {np.max(dE_demo_2):.2f}, min: {np.min(dE_demo_2):.2f}, avg: {np.mean(dE_demo_2):.2f}')\n",
    "\n",
    "dE_demo_3 = colour.delta_E(lab_values_row_first, \n",
    "                           colour.XYZ_to_Lab(XYZ_D65_values_bradford @ np.linalg.inv(color_correction_mtx_bradford).T, \n",
    "                                             illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                             )\n",
    "                           ).reshape(4,6)\n",
    "print(f'dE max: {np.max(dE_demo_3):.2f}, min: {np.min(dE_demo_3):.2f}, avg: {np.mean(dE_demo_3):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0150613",
   "metadata": {},
   "source": [
    "#### b. Acquire CC24 measurements from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c78958b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define essential parameters\n",
    "\n",
    "wb_params = awb_params # (1.87217887201, 1.27358336204, 1.0, -16.2625453031, -13.099179932, 0.0) # or awb_params calculated before\n",
    "repeats = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c0373f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n",
      "RAW Grabbed: img.max(): 4094, img.min(): 32\n",
      "After Debayer: img.max(): 65535, img.min(): 0\n"
     ]
    }
   ],
   "source": [
    "# Acquire preview image\n",
    "\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "\n",
    "mycam.open()\n",
    "raw_img = mycam.grab_raw()\n",
    "mycam.close()\n",
    "# img最大值最小值\n",
    "print(f'RAW Grabbed: img.max(): {raw_img.max()}, img.min(): {raw_img.min()}')\n",
    "img = raw_img - BLC\n",
    "img = raw_wb(img, \n",
    "             *wb_params, \n",
    "             pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "if BAYER_PATTERN == 'RGGB':\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BAYER_RGGB2RGB)\n",
    "elif BAYER_PATTERN == 'BGGR':\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BAYER_BGGR2RGB)\n",
    "print(f'After Debayer: img.max(): {img.max()}, img.min(): {img.min()}')\n",
    "img = img.astype(np.float32) / 65535\n",
    "plt.imshow(img)\n",
    "plt.title('White balanced and debayered linear device RGB image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4c0d4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 4 corners of the chart\n",
    "chart_corners = np.array([\n",
    "    [1090, 710],\n",
    "    [1490, 710],\n",
    "    [1090, 1305],\n",
    "    [1490, 1305]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4cecae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch  1: Mean RGB = ('39.02', '22.69', '17.62')\n",
      "Patch  2: Mean RGB = ('147.89', '89.46', '74.75')\n",
      "Patch  3: Mean RGB = ('48.65', '69.77', '94.32')\n",
      "Patch  4: Mean RGB = ('28.86', '33.39', '17.49')\n",
      "Patch  5: Mean RGB = ('97.30', '98.95', '140.82')\n",
      "Patch  6: Mean RGB = ('90.40', '164.51', '151.03')\n",
      "Patch  7: Mean RGB = ('147.64', '51.55', '18.95')\n",
      "Patch  8: Mean RGB = ('33.13', '54.16', '100.75')\n",
      "Patch  9: Mean RGB = ('140.12', '44.46', '46.65')\n",
      "Patch 10: Mean RGB = ('28.78', '23.40', '39.87')\n",
      "Patch 11: Mean RGB = ('102.97', '112.95', '32.14')\n",
      "Patch 12: Mean RGB = ('209.92', '101.10', '31.31')\n",
      "Patch 13: Mean RGB = ('13.55', '27.73', '59.58')\n",
      "Patch 14: Mean RGB = ('22.92', '52.27', '20.72')\n",
      "Patch 15: Mean RGB = ('106.07', '24.40', '23.38')\n",
      "Patch 16: Mean RGB = ('202.57', '123.83', '23.66')\n",
      "Patch 17: Mean RGB = ('145.02', '63.77', '97.63')\n",
      "Patch 18: Mean RGB = ('35.92', '93.21', '124.05')\n",
      "Patch 19: Mean RGB = ('240.84', '232.47', '225.74')\n",
      "Patch 20: Mean RGB = ('162.08', '161.11', '159.32')\n",
      "Patch 21: Mean RGB = ('104.22', '104.44', '103.85')\n",
      "Patch 22: Mean RGB = ('55.42', '55.23', '54.72')\n",
      "Patch 23: Mean RGB = ('24.87', '26.19', '26.64')\n",
      "Patch 24: Mean RGB = ('7.61', '9.03', '9.54')\n"
     ]
    }
   ],
   "source": [
    "# Extract 24 patches using correction_utils\n",
    "\n",
    "from correction_utils import calculate_warped_bboxes, extract_colors_warped_bbox, draw_warped_bboxes\n",
    "# 1. Calculate the warped bboxes on the original image\n",
    "# Since orientation is now locked to landscape, we use 4 rows and 6 columns.\n",
    "warped_bboxes = calculate_warped_bboxes(chart_corners, rows=4, cols=6, margin_percent=0.2)\n",
    "\n",
    "# 2. Extract mean colors directly from the original image `img`\n",
    "device_rgb_values_sample = extract_colors_warped_bbox(img, warped_bboxes)\n",
    "\n",
    "# 3. Visualize the bboxes\n",
    "# Draw the warped bboxes on the original, uncorrected image\n",
    "img_with_warped_bboxes = draw_warped_bboxes(img, warped_bboxes)\n",
    "\n",
    "# 4. Print the values\n",
    "for i, rgb in enumerate(device_rgb_values_sample):\n",
    "    rgb_255 = tuple(f'{c * 255:.2f}' for c in rgb)\n",
    "    print(f\"Patch {i+1:2d}: Mean RGB = {rgb_255}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img_with_warped_bboxes)\n",
    "plt.title(\"Warped BBoxes on Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8fcf72",
   "metadata": {},
   "source": [
    "Acquire `new measurement` or `from AWB measurement` using below cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b48959cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n"
     ]
    }
   ],
   "source": [
    "# Acquire repeat measurements\n",
    "\n",
    "from correction_utils import suppress_output\n",
    "raw_wb_slience = suppress_output(raw_wb)\n",
    "\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "mycam.open()\n",
    "\n",
    "wb_debayered_imgs = []\n",
    "for i in range(repeats):\n",
    "    raw_img = mycam.grab_raw()\n",
    "\n",
    "    # WB + Debayer\n",
    "    img = raw_img - BLC\n",
    "    img = raw_wb_slience(img, \n",
    "                *wb_params, \n",
    "                pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "    if BAYER_PATTERN == 'RGGB':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_RGGB2RGB)\n",
    "    elif BAYER_PATTERN == 'BGGR':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_BGGR2RGB)\n",
    "\n",
    "    img = img.astype(np.float32) / 65535\n",
    "\n",
    "    wb_debayered_imgs.append(img)\n",
    "mycam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00950f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR using measurements from awb run.\n",
    "from correction_utils import suppress_output\n",
    "raw_wb_slience = suppress_output(raw_wb)\n",
    "\n",
    "wb_debayered_imgs = []\n",
    "for raw_img in imgs:\n",
    "    # WB + Debayer\n",
    "    img = raw_img - BLC\n",
    "    img = raw_wb_slience(img, \n",
    "                *wb_params, \n",
    "                pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "    if BAYER_PATTERN == 'RGGB':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_RGGB2RGB)\n",
    "    elif BAYER_PATTERN == 'BGGR':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_BGGR2RGB)\n",
    "\n",
    "    img = img.astype(np.float32) / 65535\n",
    "    wb_debayered_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1ede62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_rgb_values_np.shape: (100, 24, 3)\n"
     ]
    }
   ],
   "source": [
    "# Run color extraction from 24 patches\n",
    "device_rgb_values_list = []\n",
    "for img in wb_debayered_imgs:\n",
    "    device_rgb_values = extract_colors_warped_bbox(img, warped_bboxes)\n",
    "    device_rgb_values_list.append(device_rgb_values)\n",
    "device_rgb_values_np = np.array(device_rgb_values_list)\n",
    "print(f'device_rgb_values_np.shape: {device_rgb_values_np.shape}')\n",
    "device_rgb_values = np.mean(device_rgb_values_np, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44213ca7",
   "metadata": {},
   "source": [
    "Calculate Forward Matrix, Remember using different reference $XYZ$ value ($XYZ_{D65}$ or $XYZ_{D50}$) according to your illuminant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "33a1d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correction matrix for D65 illuminant(so called Forward Matrix in DNG glossary)\n",
    "\n",
    "fwd_mtx_identical = colour.characterisation.matrix_colour_correction_Cheung2004(device_rgb_values, XYZ_D65_values_identical)\n",
    "fwd_mtx_bradford = colour.characterisation.matrix_colour_correction_Cheung2004(device_rgb_values, XYZ_D65_values_bradford)\n",
    "fwd_mtx_cat02 = colour.characterisation.matrix_colour_correction_Cheung2004(device_rgb_values, XYZ_D65_values_cat02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f39daf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate forward matrix for D50 illuminant\n",
    "\n",
    "fwd_mtx_D50 = colour.characterisation.matrix_colour_correction_Cheung2004(device_rgb_values, XYZ_D50_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57399854",
   "metadata": {},
   "source": [
    "We could evaluate the quality of colour correction matrix by calculating $dE_{00}$ between corrected and original colours.\n",
    "\n",
    "The corrected color should be carefully inversed to $Lab_{D50}$. \\\n",
    "Once the inversion is correct, the dE value should only be affected by the colour correction matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2b984a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dE00_identical: \n",
      "[[ 2.14936859  1.38759254  0.95528685  1.39314774  4.29582984  4.61182001]\n",
      " [ 3.15617394  1.42224357  2.66785247  2.73483644  1.66434273  3.26337178]\n",
      " [ 3.57171534  3.83705776  3.60024042  0.46885988  4.05948262  6.23922093]\n",
      " [ 2.79677109  2.36933029  1.42999177  1.31829602  1.73770443  4.24470393]]\n",
      "  dE max: 6.24, min: 0.47, avg: 2.72\n",
      "dE00_bradford: \n",
      "[[ 2.14936859  1.38759254  0.95528685  1.39314774  4.29582984  4.61182001]\n",
      " [ 3.15617394  1.42224357  2.66785247  2.73483644  1.66434273  3.26337178]\n",
      " [ 3.57171534  3.83705776  3.60024042  0.46885988  4.05948262  6.23922093]\n",
      " [ 2.79677109  2.36933029  1.42999177  1.31829602  1.73770443  4.24470393]]\n",
      "  dE max: 6.24, min: 0.47, avg: 2.72\n",
      "dE00_cat02: \n",
      "[[ 2.14936859  1.38759254  0.95528685  1.39314774  4.29582984  4.61182001]\n",
      " [ 3.15617394  1.42224357  2.66785247  2.73483644  1.66434273  3.26337178]\n",
      " [ 3.57171534  3.83705776  3.60024042  0.46885988  4.05948262  6.23922093]\n",
      " [ 2.79677109  2.36933029  1.42999177  1.31829602  1.73770443  4.24470393]]\n",
      "  dE max: 6.24, min: 0.47, avg: 2.72\n",
      "dE00_D50: \n",
      "[[ 2.14936859  1.38759254  0.95528685  1.39314774  4.29582984  4.61182001]\n",
      " [ 3.15617394  1.42224357  2.66785247  2.73483644  1.66434273  3.26337178]\n",
      " [ 3.57171534  3.83705776  3.60024042  0.46885988  4.05948262  6.23922093]\n",
      " [ 2.79677109  2.36933029  1.42999177  1.31829602  1.73770443  4.24470393]]\n",
      "  dE max: 6.24, min: 0.47, avg: 2.72\n"
     ]
    }
   ],
   "source": [
    "# Calculate dE00 of nominal values and corrected values\n",
    "\n",
    "CC24_XYZ_corrected_identical = device_rgb_values @ fwd_mtx_identical.T\n",
    "CC24_XYZ_corrected_bradford = device_rgb_values @ fwd_mtx_bradford.T\n",
    "CC24_XYZ_corrected_cat02 = device_rgb_values @ fwd_mtx_cat02.T\n",
    "CC24_XYZ_corrected_D50 = device_rgb_values @ fwd_mtx_D50.T\n",
    "\n",
    "dE00_identical = colour.delta_E(lab_values_row_first, \n",
    "                      colour.XYZ_to_Lab(CC24_XYZ_corrected_identical, \n",
    "                                        illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65']\n",
    "                                        )\n",
    "                     )\n",
    "dE00_bradford = colour.delta_E(lab_values_row_first, \n",
    "                      colour.XYZ_to_Lab(CC24_XYZ_corrected_bradford @ np.linalg.inv(color_correction_mtx_bradford).T, \n",
    "                                        illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                        )\n",
    "                     )\n",
    "dE00_cat02 = colour.delta_E(lab_values_row_first, \n",
    "                      colour.XYZ_to_Lab(CC24_XYZ_corrected_cat02 @ np.linalg.inv(color_correction_mtx_cat02).T, \n",
    "                                        illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                        )\n",
    "                     )\n",
    "dE00_D50 = colour.delta_E(lab_values_row_first, \n",
    "                      colour.XYZ_to_Lab(CC24_XYZ_corrected_D50, \n",
    "                                        illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                        )\n",
    "                     )\n",
    "\n",
    "print(f'dE00_identical: \\n{dE00_identical.reshape(4,6)}')\n",
    "print(f'  dE max: {np.max(dE00_identical):.2f}, min: {np.min(dE00_identical):.2f}, avg: {np.mean(dE00_identical):.2f}')\n",
    "print(f'dE00_bradford: \\n{dE00_bradford.reshape(4,6)}')\n",
    "print(f'  dE max: {np.max(dE00_bradford):.2f}, min: {np.min(dE00_bradford):.2f}, avg: {np.mean(dE00_bradford):.2f}')\n",
    "print(f'dE00_cat02: \\n{dE00_cat02.reshape(4,6)}')\n",
    "print(f'  dE max: {np.max(dE00_cat02):.2f}, min: {np.min(dE00_cat02):.2f}, avg: {np.mean(dE00_cat02):.2f}')\n",
    "print(f'dE00_D50: \\n{dE00_D50.reshape(4,6)}')\n",
    "print(f'  dE max: {np.max(dE00_D50):.2f}, min: {np.min(dE00_D50):.2f}, avg: {np.mean(dE00_D50):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9db5f037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct inversion of Bradford to Lab at D65:\n",
      "  dE max: 7.73, min: 1.34, avg: 3.16\n",
      "Direct inversion of CAT02 to Lab at D65:\n",
      "  dE max: 7.72, min: 1.34, avg: 3.17\n"
     ]
    }
   ],
   "source": [
    "# If the Lab value is not perfectly inverse, it may can reflect the actual performance\n",
    "dE00_bradford_direct_lab = colour.delta_E(lab_values_row_first, \n",
    "                             colour.XYZ_to_Lab(CC24_XYZ_corrected_bradford, \n",
    "                               illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65']\n",
    "                               )\n",
    "                             )\n",
    "dE00_cat02_direct_lab = colour.delta_E(lab_values_row_first, \n",
    "                             colour.XYZ_to_Lab(CC24_XYZ_corrected_cat02, \n",
    "                               illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65']\n",
    "                               )\n",
    "                             )\n",
    "print('Direct inversion of Bradford to Lab at D65:')\n",
    "print(f'  dE max: {np.max(dE00_bradford_direct_lab):.2f}, min: {np.min(dE00_bradford_direct_lab):.2f}, avg: {np.mean(dE00_bradford_direct_lab):.2f}')\n",
    "print('Direct inversion of CAT02 to Lab at D65:')\n",
    "print(f'  dE max: {np.max(dE00_cat02_direct_lab):.2f}, min: {np.min(dE00_cat02_direct_lab):.2f}, avg: {np.mean(dE00_cat02_direct_lab):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc2bd8",
   "metadata": {},
   "source": [
    "But the sRGB value **will** be affected by different chromatic adaptation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6c412025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[109  78  65 110  78  65]\n",
      " [199 148 131 202 148 131]\n",
      " [ 93 122 155  86 123 155]\n",
      " [ 87 105  62  90 105  63]\n",
      " [145 137 186 140 138 185]\n",
      " [119 204 188 117 204 188]\n",
      " [209 119  44 214 119  44]\n",
      " [ 62  90 162  38  92 162]\n",
      " [202  88 104 205  89 103]\n",
      " [ 85  59 105  81  60 104]\n",
      " [161 192  69 170 191  71]\n",
      " [240 172  57 247 171  59]\n",
      " [ 15  56 129 -50  58 128]\n",
      " [ 61 136  66  68 135  67]\n",
      " [181  59  70 184  60  70]\n",
      " [234 197  10 243 196  20]\n",
      " [198  93 155 198  95 154]\n",
      " [ 28 144 177 -52 144 176]\n",
      " [229 228 223 230 228 223]\n",
      " [191 193 191 191 193 191]\n",
      " [156 159 158 156 159 158]\n",
      " [117 119 118 117 119 118]\n",
      " [ 79  83  84  78  83  84]\n",
      " [ 41  48  50  40  48  50]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate sRGB value in 8bit using different adaptation transforms\n",
    "CC24_sRGB_corrected_identical = colour.XYZ_to_sRGB(CC24_XYZ_corrected_identical)\n",
    "CC24_sRGB_corrected_bradford = colour.XYZ_to_sRGB(CC24_XYZ_corrected_bradford)\n",
    "\n",
    "print(np.hstack(((CC24_sRGB_corrected_bradford * 255).astype(int), \n",
    "      (CC24_sRGB_corrected_identical * 255).astype(int)))\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e1ded6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.75569544462..1.07972067847].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.49777219555..1.08642675732].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.51039416756..1.08421100348].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.49777219555..1.08642675732].\n"
     ]
    }
   ],
   "source": [
    "# Validate correction by performing a forward transformation to sRGB\n",
    "img_XYZ_corrected_identical = img @ fwd_mtx_identical.T\n",
    "img_XYZ_corrected_bradford = img @ fwd_mtx_bradford.T\n",
    "img_XYZ_corrected_cat02 = img @ fwd_mtx_cat02.T\n",
    "img_XYZ_corrected_D50 = img @ fwd_mtx_D50.T\n",
    "\n",
    "img_sRGB_identical = colour.XYZ_to_sRGB(img_XYZ_corrected_identical, chromatic_adaptation_transform='Bradford', apply_cctf_encoding=True)\n",
    "img_sRGB_bradford = colour.XYZ_to_sRGB(img_XYZ_corrected_bradford, chromatic_adaptation_transform='Bradford', apply_cctf_encoding=True)\n",
    "img_sRGB_cat02 = colour.XYZ_to_sRGB(img_XYZ_corrected_cat02, chromatic_adaptation_transform='Bradford', apply_cctf_encoding=True)\n",
    "img_sRGB_D50 = colour.XYZ_to_sRGB(img_XYZ_corrected_D50, illuminant=colour.CCS_ILLUMINANTS[\"CIE 1931 2 Degree Standard Observer\"][\"D50\"], chromatic_adaptation_transform='Bradford', apply_cctf_encoding=True)\n",
    "# The chromatic_adaptation_transform should not affect anything since the sRGB is D65 based.\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(20, 5))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image (linear, device RGB)')\n",
    "ax1.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax1.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax2.imshow(img_sRGB_identical)\n",
    "ax2.set_title('Corrected Image (Implicit Identical)')\n",
    "ax2.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax2.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax3.imshow(img_sRGB_bradford)\n",
    "ax3.set_title('Corrected Image (Bradford)')\n",
    "ax3.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax3.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax4.imshow(img_sRGB_cat02)\n",
    "ax4.set_title('Corrected Image (CAT02)')\n",
    "ax4.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax4.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax5.imshow(img_sRGB_D50)\n",
    "ax5.set_title('Corrected Image (D50)')\n",
    "ax5.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax5.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5e877",
   "metadata": {},
   "source": [
    "#### b2. Conclusion\n",
    "Visually, the CAT02 method is the best.\n",
    "\n",
    "We visualize the whole process of RAW development here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b84a01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative efficient calculation (using CAT02 as example) showing the whole process:\n",
    "\n",
    "from correction_utils import linear_to_srgb\n",
    "\n",
    "device_RGB_to_linear_sRGB = colour.RGB_COLOURSPACES['sRGB'].matrix_XYZ_to_RGB @ fwd_mtx_cat02\n",
    "img_sRGB_cat02_linear = np.clip(img @ device_RGB_to_linear_sRGB.T, 0, 1)\n",
    "img_sRGB_cat02 = linear_to_srgb(img_sRGB_cat02_linear)\n",
    "\n",
    "fig, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(2, 4, figsize=(16, 10))\n",
    "ax1.imshow(raw_img)\n",
    "ax1.set_title(\"RAW Image\")\n",
    "ax1.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax1.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax2.imshow(img)\n",
    "ax2.set_title(\"WB+Debayered Image (Linear)\")\n",
    "ax2.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax2.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax3.imshow(img_sRGB_cat02_linear)\n",
    "ax3.set_title(\"CAT02+Cheung2004 Fwd Corr. Img. (Linear)\")\n",
    "ax3.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax3.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax4.imshow(img_sRGB_cat02)\n",
    "ax4.set_title(\"CAT02+Cheung2004 Fwd Corr. Img. (sRGB)\")\n",
    "ax4.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax4.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax5.imshow(cv2.cvtColor(raw_img, cv2.COLOR_BAYER_RG2RGB)/4096)\n",
    "ax5.set_title('Debayer Only (Device RGB)')\n",
    "ax5.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax5.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax6.imshow(linear_to_srgb(img))\n",
    "ax6.set_title('WB+Debayered in sRGB gamma')\n",
    "ax6.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax6.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6b7f7",
   "metadata": {},
   "source": [
    "#### b3. Optimize calculation process to accelerate the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e4a2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe a C extension.\n",
    "# Implemented 250731 13ms/2448x2048@12bit, uint16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44548b9c",
   "metadata": {},
   "source": [
    "#### c. Using customized loss function (dE2000 based) to calculate forward matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3b7e6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  100, Loss (dE2000**3): 29.8698\n",
      "Iteration  200, Loss (dE2000**3): 29.0780\n",
      "Iteration  300, Loss (dE2000**3): 29.0619\n",
      "Iteration  400, Loss (dE2000**3): 29.0275\n",
      "Iteration  500, Loss (dE2000**3): 28.9932\n",
      "Iteration  600, Loss (dE2000**3): 28.9136\n",
      "Iteration  700, Loss (dE2000**3): 28.9129\n",
      "Iteration  800, Loss (dE2000**3): 28.9113\n",
      "Iteration  900, Loss (dE2000**3): 28.9103\n",
      "Iteration 1000, Loss (dE2000**3): 28.9095\n",
      "Iteration 1100, Loss (dE2000**3): 28.9091\n",
      "Iteration 1200, Loss (dE2000**3): 28.9091\n",
      "\n",
      "Optimization finished.\n",
      "Final Loss (dE2000**3): 28.9091\n"
     ]
    }
   ],
   "source": [
    "# A good initial value is essential for better dE.\n",
    "\n",
    "sigma_init = 0.01\n",
    "\n",
    "from correction_utils import forward_matrix_slover\n",
    "\n",
    "fwd_mtx_custom_solver, final_loss = forward_matrix_slover(device_rgb_values, XYZ_D50_values, \n",
    "                                                   illuminant='D50',\n",
    "                                                   initial_matrix=fwd_mtx_cat02+np.random.normal(0, sigma_init, size=(3,3)),\n",
    "                                                   extra_illuminant_transform_XYZ=np.linalg.inv(color_correction_mtx_cat02),\n",
    "                                                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30a1b2",
   "metadata": {},
   "source": [
    "#### d. Compare the results and choose which one to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c1cdc279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom forward_matrix: \n",
      "[[ 0.45529346  0.36683375 -0.05683137]\n",
      " [ 0.16103211  0.96855913 -0.31887464]\n",
      " [-0.05394204  0.10245696  0.83165559]]\n",
      "fwd_mtx by colour-science(CAT02): \n",
      "[[ 0.44424848  0.39056233 -0.04470691]\n",
      " [ 0.16628298  0.96361235 -0.29148462]\n",
      " [-0.03554016  0.08221551  0.86970827]]\n",
      "fwd_mtx_D50(assuming) by colour-science: \n",
      "[[ 0.47017549  0.4326151  -0.10154605]\n",
      " [ 0.17720008  0.97233676 -0.31134601]\n",
      " [-0.02816038  0.05887986  0.66358337]]\n",
      "dE00 from custom forward matrix:\n",
      "[ 1.73525381  0.69568713  0.42514404  1.85008685  3.70906528  3.83687584\n",
      "  3.35169846  2.00752069  1.87374147  2.05645065  1.69274227  3.05251664\n",
      "  4.44674241  3.89367722  2.79236399  0.798067    2.83195635  4.76514187\n",
      "  3.66534688  3.0294655   2.07390965  1.78825611  1.77853926  4.35435959]\n",
      "  dE max: 4.77, min: 0.43, avg: 2.60\n",
      "dE00 from CAT02:\n",
      "[ 2.89539661  1.74497969  2.72530126  2.39678093  5.51022171  4.74126576\n",
      "  4.20233577  3.02833127  2.50188596  1.39302777  2.75233232  3.16552301\n",
      "  3.68006258  3.84936748  3.87598162  2.60658794  3.92906129  7.71621125\n",
      "  2.72867686  2.40464126  1.43596321  1.33860056  1.56232708  3.90919989]\n",
      "  dE max: 7.72, min: 1.34, avg: 3.17\n",
      "dE00 assuming illuminant is D50:\n",
      "[ 2.14936859  1.38759254  0.95528685  1.39314774  4.29582984  4.61182001\n",
      "  3.15617394  1.42224357  2.66785247  2.73483644  1.66434273  3.26337178\n",
      "  3.57171534  3.83705776  3.60024042  0.46885988  4.05948262  6.23922093\n",
      "  2.79677109  2.36933029  1.42999177  1.31829602  1.73770443  4.24470393]\n",
      "  dE max: 6.24, min: 0.47, avg: 2.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.49777219555..1.08642675732].\n"
     ]
    }
   ],
   "source": [
    "# Print and render results\n",
    "print('custom forward_matrix: ')\n",
    "print(fwd_mtx_custom_solver)\n",
    "\n",
    "print('fwd_mtx by colour-science(CAT02): ')\n",
    "print(fwd_mtx_cat02)\n",
    "\n",
    "print('fwd_mtx_D50(assuming) by colour-science: ')\n",
    "print(fwd_mtx_D50)\n",
    "\n",
    "CC24_XYZ_corrected_custom_fwd = device_rgb_values @ fwd_mtx_custom_solver.T\n",
    "\n",
    "dE00_custom_fwd_direct_lab = colour.delta_E(lab_values_row_first, \n",
    "                               colour.XYZ_to_Lab(CC24_XYZ_corrected_custom_fwd @ np.linalg.inv(color_correction_mtx_cat02).T, \n",
    "                                 illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                 )\n",
    "                               )\n",
    "\n",
    "print('dE00 from custom forward matrix:')\n",
    "print(dE00_custom_fwd_direct_lab)\n",
    "print(f'  dE max: {np.max(dE00_custom_fwd_direct_lab):.2f}, min: {np.min(dE00_custom_fwd_direct_lab):.2f}, avg: {np.mean(dE00_custom_fwd_direct_lab):.2f}')\n",
    "print('dE00 from CAT02:')\n",
    "print(dE00_cat02_direct_lab)\n",
    "print(f'  dE max: {np.max(dE00_cat02_direct_lab):.2f}, min: {np.min(dE00_cat02_direct_lab):.2f}, avg: {np.mean(dE00_cat02_direct_lab):.2f}')\n",
    "print('dE00 assuming illuminant is D50:')\n",
    "print(dE00_D50)\n",
    "print(f'  dE max: {np.max(dE00_D50):.2f}, min: {np.min(dE00_D50):.2f}, avg: {np.mean(dE00_D50):.2f}')\n",
    "\n",
    "img_sRGB_custom_fwd = linear_to_srgb(np.clip(img @ fwd_mtx_custom_solver.T @ colour.RGB_COLOURSPACES['sRGB'].matrix_XYZ_to_RGB.T, 0, 1))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax1.imshow(img_sRGB_custom_fwd)\n",
    "ax1.set_title(\"Custom Forward Matrix\")\n",
    "ax1.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax1.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax1.axis('off')\n",
    "ax2.imshow(img_sRGB_cat02)\n",
    "ax2.set_title(\"CAT02 Forward Matrix\")\n",
    "ax2.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax2.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax2.axis('off')\n",
    "ax3.imshow(img_sRGB_D50)\n",
    "ax3.set_title(\"D50 Forward Matrix\")\n",
    "ax3.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax3.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax3.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e92359c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bases of the device RGB space in XYZ color model.\n",
    "\n",
    "# Note on linear algebra: the conversion matrix which map points from space A to B, \n",
    "# literally equals to horizontal stacks of bases of space A in the coordinates of space B.\n",
    "# (Here, we assume all vectors are vertically arranged.)\n",
    "\n",
    "fig, ax = colour.plotting.plot_RGB_colourspaces_gamuts('sRGB', 'CIE XYZ')\n",
    "ax.scatter(fwd_mtx_custom_solver[:, 0], fwd_mtx_custom_solver[:, 1], fwd_mtx_custom_solver[:, 2], c = ('red', 'green', 'blue'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a574748",
   "metadata": {},
   "source": [
    "#### e. Choose and save correction results in numpy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "62a23c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLC': 32, 'ADC_MAX_LEVEL': 4095, 'wb_params': (1.6787903361861161, 1.317738540482605, 1.0, 6.4110853452379093, -3.5191075359020805, 0.0), 'fwd_mtx': array([[ 0.44424848,  0.39056233, -0.04470691],\n",
      "       [ 0.16628298,  0.96361235, -0.29148462],\n",
      "       [-0.03554016,  0.08221551,  0.86970827]]), 'Notes': 'D50 15% power, vertical illuminant, 10ms exposure, Analog Gain 1.0, 8mm Lens, IMX264, 5MP'}\n"
     ]
    }
   ],
   "source": [
    "# Save tag: BLC, ADC_MAX_LEVEL, wb_params, fwd_mtx and Notes\n",
    "\n",
    "Notes = 'D50 15% power, vertical illuminant, 10ms exposure, Analog Gain 1.0, 8mm Lens, IMX264, 5MP'\n",
    "mtx_to_save = fwd_mtx_cat02\n",
    "filename = 'correction_results_D50_250805.npy'\n",
    "\n",
    "np.save(filename, {'BLC': BLC, 'ADC_MAX_LEVEL': ADC_MAX_LEVEL,\n",
    "                                   'wb_params': wb_params, 'fwd_mtx': mtx_to_save, \n",
    "                                   'Notes': Notes\n",
    "                                   })\n",
    "\n",
    "# Read back and check\n",
    "data = np.load(filename, allow_pickle=True).item()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c123773",
   "metadata": {},
   "source": [
    "`wb_params`: (R_gain, G_gain, B_gain, R_dBLC, G_dBLC, B_dBLC)\n",
    "\n",
    "`fwd_mtx`: Transform from device RGB to $XYZ$ in given illuminant (e.g. D50). \n",
    "The user should calculate chromatic (illuminant) adaptation and $XYZ$->sRGB itself.\n",
    "如果已经wb，是否还需要改变fwd_mtx? 可能有微调。测试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5b18ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.8538751110194334, 1.2618050211142049, 1.0, -14.453442776099127, -11.818613731445266, 0.0)\n",
      "(1.6232238624261359, 1.3050488646488514, 1.0, -6.6773836516730469, -8.8718066707359053, 0.0)\n",
      "[[ 0.48400457  0.49366056 -0.12875313]\n",
      " [ 0.11755779  1.14741225 -0.35974064]\n",
      " [-0.10007283  0.26020384  0.80710571]]\n",
      "[[ 0.51162398  0.57441403 -0.13854522]\n",
      " [ 0.15561742  1.30252441 -0.44838334]\n",
      " [-0.09894102  0.17512108  1.0111746 ]]\n"
     ]
    }
   ],
   "source": [
    "data1 = np.load('correction_results_D65_250731.npy', allow_pickle=True).item()\n",
    "data2 = np.load('correction_results_D50_250731.npy', allow_pickle=True).item()\n",
    "print(data1['wb_params'])\n",
    "print(data2['wb_params'])\n",
    "print(data1['fwd_mtx'])\n",
    "print(data2['fwd_mtx'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
