{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c6ae2b",
   "metadata": {},
   "source": [
    "## Calculate Raw image correction paramters\n",
    "*Author: Haiyun Huang 2025 with Deepseek*\n",
    "\n",
    "This document aims to acquire mathmatically accurate correction parameters for raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003d3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4230b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mvsdk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from huateng_camera_v2_tc_mod import Camera\n",
    "from raw_processing import raw_awb, raw_wb\n",
    "from correction_utils import suppress_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f40857",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPOSURE_TIME = 10 # ms\n",
    "ADC_MAX_LEVEL = 2**12 - 1 # No greater than 65535"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb0289",
   "metadata": {},
   "source": [
    "### 01. Acquiring AWB Correction Parameters\n",
    "The WB process will do:\n",
    "- (optional) extra dBLC, \n",
    "- clipping to per channel max level, \n",
    "- scales the RAW channels to 16bit.\n",
    "\n",
    "Acquiring params including:\n",
    "- (optional) RGB dBLC (after BLC), \n",
    "- RGB gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "716ad2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n",
      "RAW Grabbed: img.max(): 4094, img.min(): 32\n"
     ]
    }
   ],
   "source": [
    "# Acquire preview image\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "\n",
    "mycam.open()\n",
    "raw_img = mycam.grab_raw()\n",
    "mycam.close()\n",
    "# img最大值最小值\n",
    "print(f'RAW Grabbed: img.max(): {raw_img.max()}, img.min(): {raw_img.min()}')\n",
    "plt.imshow(raw_img)\n",
    "plt.title('RAW Preview')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f517e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting essential params for acquiring correction params\n",
    "repeats = 100\n",
    "BLC = 32\n",
    "BAYER_PATTERN = 'BGGR'\n",
    "\n",
    "# 白平衡\n",
    "# 定义两个ROI用于自动白平衡\n",
    "# ROI 1 (亮区)\n",
    "x_slice_1 = slice(1460, 1500)\n",
    "y_slice_1 = slice(920, 960)\n",
    "awb_roi_1 = (y_slice_1, x_slice_1) # y,x\n",
    "\n",
    "# ROI 2 (暗区)\n",
    "x_slice_2 = slice(1460, 1500)\n",
    "y_slice_2 = slice(1120, 1160)\n",
    "awb_roi_2 = (y_slice_2, x_slice_2) # y,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3a37c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n"
     ]
    }
   ],
   "source": [
    "# Acquire images\n",
    "\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "mycam.open()\n",
    "\n",
    "imgs = []\n",
    "for i in range(repeats):\n",
    "    img = mycam.grab_raw()\n",
    "    imgs.append(img)\n",
    "mycam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dad86ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AWB params: (mean ± SE)\n",
      "R gain: 1.8722 ± 0.0005\n",
      "G gain: 1.2736 ± 0.0002\n",
      "B gain: 1.0000 ± 0.0000\n",
      "R dBLC: -16.2625 ± 0.2017\n",
      "G dBLC: -13.0992 ± 0.2143\n",
      "B dBLC: 0.0000 ± 0.0000\n",
      "Copy format: (1.87217887201, 1.27358336204, 1.0, -16.2625453031, -13.099179932, 0.0)\n",
      "Parameters saved in variable `awb_params`\n"
     ]
    }
   ],
   "source": [
    "# Calculate avg. correction parameters\n",
    "raw_awb_slience = suppress_output(raw_awb)\n",
    "\n",
    "awb_params_list = []\n",
    "for img in imgs:\n",
    "    # basic BLC\n",
    "    img_BLC = img - BLC\n",
    "    # AWB\n",
    "    _, awb_params = raw_awb_slience(img_BLC, awb_roi_1, awb_roi_2, pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "    awb_params_list.append(awb_params)\n",
    "awb_params_np = np.array(awb_params_list)\n",
    "awb_params_avg = np.mean(awb_params_np, axis=0)\n",
    "awb_params_se = np.std(awb_params_np, ddof=1, axis=0)/np.sqrt(repeats)\n",
    "\n",
    "print('Average AWB params: (mean ± SE)')\n",
    "print(f'R gain: {awb_params_avg[0]:.4f} ± {awb_params_se[0]:.4f}')\n",
    "print(f'G gain: {awb_params_avg[1]:.4f} ± {awb_params_se[1]:.4f}')\n",
    "print(f'B gain: {awb_params_avg[2]:.4f} ± {awb_params_se[2]:.4f}')\n",
    "print(f'R dBLC: {awb_params_avg[3]:.4f} ± {awb_params_se[3]:.4f}')\n",
    "print(f'G dBLC: {awb_params_avg[4]:.4f} ± {awb_params_se[4]:.4f}')\n",
    "print(f'B dBLC: {awb_params_avg[5]:.4f} ± {awb_params_se[5]:.4f}')\n",
    "print(f'Copy format: ({', '.join(map(str, awb_params_avg))})')\n",
    "awb_params = tuple(awb_params_np)\n",
    "print('Parameters saved in variable `awb_params`')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d19fc",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "D65 Room LED Light\n",
    "> Average AWB params: (mean ± SE)\n",
    "`R gain`: 1.8722 ± 0.0005\\\n",
    "`G gain`: 1.2736 ± 0.0002\\\n",
    "`B gain`: 1.0000 ± 0.0000\\\n",
    "`R dBLC`: -16.2625 ± 0.2017\\\n",
    "`G dBLC`: -13.0992 ± 0.2143\\\n",
    "`B dBLC`: 0.0000 ± 0.0000\\\n",
    "Copy format: `(1.87217887201, 1.27358336204, 1.0, -16.2625453031, -13.099179932, 0.0)`\n",
    "\n",
    "D50 Sunlike Light (10ms exposure, white patch ~ 3000-4000 DN @ 12bit)\n",
    "> Average AWB params: (mean ± SE)\n",
    "`R gain`: 1.6381 ± 0.0005\\\n",
    "`G gain`: 1.3063 ± 0.0003\\\n",
    "`B gain`: 1.0000 ± 0.0000\\\n",
    "`R dBLC`: -1.8557 ± 0.2299\\\n",
    "`G dBLC`: -6.9159 ± 0.2183\\\n",
    "`B dBLC`: 0.0000 ± 0.0000\\\n",
    "Copy format: `(1.63808680867, 1.30625734229, 1.0, -1.8556998082, -6.91589560617, 0.0)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8a97f",
   "metadata": {},
   "source": [
    "### 02. Calculate Forward Matrix\n",
    "Transform colors from device $RGB$ to $XYZ_{D50}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b84986",
   "metadata": {},
   "source": [
    "#### a1. Preparing ColorChecker24 Reference Data\n",
    "Convert reference $Lab_{D50}$ data to $XYZ$ for given illuminant by *Bradford* + *von Keris* method.\n",
    "\n",
    "The reference ColorChecker24 patches are measured under D50 illuminant in $Lab_{D50}$ format\\\n",
    "We need to transform such refernece $Lab$ value to $XYZ$ space under the constraint of D50 illuminant.\n",
    "\n",
    "The layout of CC24: 4 rows, 6 columns. `A1` is at upper left, `F4` is at lower right.\n",
    "\n",
    "多解释一些：\n",
    "1. 对于反射式测试卡，反射率是其本质，而对于传感器，光谱辐照是其本质。\n",
    "2. D50照明定义了照明谱，只有在给定照明谱的情况下，才能拿到光谱辐照，拿到加色性的XYZ值。\n",
    "3. 这也是为什么测试卡用Lab标注值，而不是XYZ，因为XYZ会随着照明不同而改变。但Lab是归一化到白点（*相对*稳定，此为von Kries假设下的方法），并且定义了测量白点是D50（Lab空间需要给定白点才在辐照水平有意义）。\n",
    "4. $XYZ_{D50}$的下标并没有实际意义，因为XYZ空间不依赖白点而存在，只是为了表示是D50照明下获得的值。\n",
    "5. 对于不同白点的转换，常用Bradford比色法，主要是将XYZ值转移到LMS空间后缩放。不同比色法定义的这个转移矩阵$M_A$不同。\n",
    "6. 对于更精确的应用，应当直接从各色块的反射率曲线推导给定光源（如D65）下的XYZ值，而不是用$Lab_{D50}$通过Bradford。 参见：https://babelcolor.com/colorchecker-2.htm#xl_CCP2_images\n",
    "7. 由于新版ColorChecker24没有平均的反射率曲线可用，本文档推荐使用Bradford比色法处理照明非D50的情况。\n",
    "\n",
    "The basic idea is, transforming $XYZ$ to physiologically relavent $LMS$ space, scaling in $LMS$ space (based on *von Kries* hypothesis), and then transform back.\\\n",
    "There are multiple options of matirx for $XYZ$ to $LMS$, probably because of different illuminant spectra,\\\n",
    "including *Identical*, *Bradford* methods, etc.\\\n",
    "See documents of `colour.adaptation.CAT_*` for more methods based on *von Kries* hypothesis.\n",
    "\n",
    "See more mathmatical details:\n",
    "  1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/bradford_e.html\\\n",
    "  2. http://www.brucelindbloom.com/index.html?Eqn_ChromAdapt.html\\\n",
    "\n",
    "For information about XYZ-Lab transformation, see: \n",
    "  1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/colorspace3_e.html\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43292044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the illuminant of the calibration images, CIE 1931 XYZ value.\n",
    "\n",
    "import colour\n",
    "\n",
    "illuminant = colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d75b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1' 'B1' 'C1' 'D1' 'E1' 'F1' 'A2' 'B2' 'C2' 'D2' 'E2' 'F2' 'A3' 'B3' 'C3'\n",
      " 'D3' 'E3' 'F3' 'A4' 'B4' 'C4' 'D4' 'E4' 'F4']\n",
      "[[  3.75400000e+01   1.43700000e+01   1.49200000e+01]\n",
      " [  6.46600000e+01   1.92700000e+01   1.75000000e+01]\n",
      " [  4.93200000e+01  -3.82000000e+00  -2.25400000e+01]\n",
      " [  4.34600000e+01  -1.27400000e+01   2.27200000e+01]\n",
      " [  5.49400000e+01   9.61000000e+00  -2.47900000e+01]\n",
      " [  7.04800000e+01  -3.22600000e+01  -3.70000000e-01]\n",
      " [  6.27300000e+01   3.58300000e+01   5.65000000e+01]\n",
      " [  3.94300000e+01   1.07500000e+01  -4.51700000e+01]\n",
      " [  5.05700000e+01   4.86400000e+01   1.66700000e+01]\n",
      " [  3.01000000e+01   2.25400000e+01  -2.08700000e+01]\n",
      " [  7.17700000e+01  -2.41300000e+01   5.81900000e+01]\n",
      " [  7.15100000e+01   1.82400000e+01   6.73700000e+01]\n",
      " [  2.83700000e+01   1.54200000e+01  -4.98000000e+01]\n",
      " [  5.43800000e+01  -3.97200000e+01   3.22700000e+01]\n",
      " [  4.24300000e+01   5.10500000e+01   2.86200000e+01]\n",
      " [  8.18000000e+01   2.67000000e+00   8.04100000e+01]\n",
      " [  5.06300000e+01   5.12800000e+01  -1.41200000e+01]\n",
      " [  4.95700000e+01  -2.97100000e+01  -2.83200000e+01]\n",
      " [  9.51900000e+01  -1.03000000e+00   2.93000000e+00]\n",
      " [  8.12900000e+01  -5.70000000e-01   4.40000000e-01]\n",
      " [  6.68900000e+01  -7.50000000e-01  -6.00000000e-02]\n",
      " [  5.07600000e+01  -1.30000000e-01   1.40000000e-01]\n",
      " [  3.56300000e+01  -4.60000000e-01  -4.80000000e-01]\n",
      " [  2.06400000e+01   7.00000000e-02  -4.60000000e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Loading ColorChecker24 Lab_D50 value from X-rite data(after 2015)\n",
    "import numpy as np\n",
    "\n",
    "def parse_data_file(file_path):\n",
    "    # Deepseek\n",
    "    # 初始化存储变量\n",
    "    string_list = []\n",
    "    numeric_data = []\n",
    "    \n",
    "    # 标志是否开始/结束读取数据\n",
    "    reading_data = False\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # 去除首尾空白字符\n",
    "            \n",
    "            if not reading_data:\n",
    "                if line == 'BEGIN_DATA':\n",
    "                    reading_data = True\n",
    "                continue\n",
    "            else:\n",
    "                if line == 'END_DATA':\n",
    "                    break\n",
    "                \n",
    "                # 分割数据行\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) != 4:\n",
    "                    continue  # 跳过格式不正确的行\n",
    "                \n",
    "                # 解析数据\n",
    "                string_part = parts[0]\n",
    "                try:\n",
    "                    numeric_parts = [float(x) for x in parts[1:4]]\n",
    "                except ValueError:\n",
    "                    continue  # 跳过数值转换失败的行\n",
    "                \n",
    "                # 存储数据\n",
    "                string_list.append(string_part)\n",
    "                numeric_data.append(numeric_parts)\n",
    "    \n",
    "    # 将数值数据转换为N×3的NumPy数组\n",
    "    numeric_array = np.array(numeric_data)\n",
    "    \n",
    "    return string_list, numeric_array\n",
    "\n",
    "patch_name, lab_values = parse_data_file('RefPatches.txt')\n",
    "# The value is column first, where A* is the first column.\n",
    "patch_name_row_first = np.array(patch_name).reshape(4, 6, order='F').ravel(order='C')\n",
    "lab_values_row_first = lab_values.reshape((4, 6, 3), order='F').reshape((-1, 3), order='C')\n",
    "print(patch_name_row_first)\n",
    "print(lab_values_row_first)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77ca403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34891221  0.36417406]\n"
     ]
    }
   ],
   "source": [
    "# Transform Lab_D50 to XYZ_D50 using colour-science package\n",
    "\n",
    "XYZ_D50_values = colour.Lab_to_XYZ(lab_values_row_first, \n",
    "                                   illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']) # Lab measured in D50\n",
    "# The D50 subscript indicates that the XYZ values are obtained under the D50 illuminant.\n",
    "# print(XYZ_D50_values)\n",
    "print(colour.XYZ_to_xy(XYZ_D50_values[18])) # the brightest white patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c1e3b",
   "metadata": {},
   "source": [
    "The XYZ values could be transform to other illuminant by:\n",
    "  1. Implicitly using *Identical* matrix (NOT recommanded) for XYZ to LMS transform, then scaling under *von Kries* hypothesis.\\\n",
    "     This can be done by changing the `illuminant` parameter in `Lab_to_XYZ` function.\\\n",
    "     Also see the document and the source code of `Lab_to_XYZ` function. (https://colour.readthedocs.io/en/develop/_modules/colour/models/cie_lab.html#Lab_to_XYZ)\\\n",
    "\n",
    "  2. Explicitly using *Bradford* matrix or other matrix (such as *CAT02*) to transform.\n",
    "\n",
    "The area prefers *Bradford* method (For historical reason? maybe have a look for *CAT02* matrix), but it would be better if we can **measure the spectra** for the chart.\n",
    "\n",
    "We have generated $XYZ_{D65}$ values by all three methods below for the CC24 chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f8d614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Manually written Lab to XYZ_D50 transformation\n",
    "\n",
    "def lab_to_xyz_d50(lab_values):\n",
    "    # The basic idea is, transforming XYZ to physiologically relavent LMS space, scaling in LMS space, and then transform back.\n",
    "    # There are multiple options of matirx for XYZ to LMS, probably because of different illuminant spectra.\n",
    "    # including Identical, Bradford and Von Kries\n",
    "    # See also: \n",
    "    #   1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/bradford_e.html\n",
    "    #   2. http://www.brucelindbloom.com/index.html?Eqn_ChromAdapt.html\n",
    "    # For information about XYZ-Lab transformation, see: \n",
    "    #   1. https://fujiwaratko.sakura.ne.jp/infosci/colorspace/colorspace3_e.html\n",
    "    \n",
    "    # Using Bradford M_A matrix for XYZ-LMS conversion\n",
    "    M_A = np.array([\n",
    "        [0.8951, 0.2664, -0.1614],\n",
    "        [-0.7502, 1.7135, 0.0367],\n",
    "        [0.0389, -0.0685, 1.0296]\n",
    "    ])\n",
    "    # 定义D50white point\n",
    "    D50 = np.array([96.42, 100.0, 82.52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fbc7be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White patch(0.05D):\n",
      "Identical xy: [ 0.31644451  0.33509554]\n",
      "Bradford xy: [ 0.31606103  0.33525624]\n",
      "CAT02 xy: [ 0.31598245  0.33513653]\n"
     ]
    }
   ],
   "source": [
    "# Transform XYZ (D50 illuminant) to XYZ (D65 illuminant)\n",
    "\n",
    "# Method 1. Change illuminant when Lab->XYZ (implicitly)\n",
    "XYZ_D65_values_identical = colour.Lab_to_XYZ(lab_values_row_first, illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])\n",
    "\n",
    "# Method 2. Change illuminant under XYZ using Bradford\n",
    "color_correction_mtx_bradford = colour.adaptation.matrix_chromatic_adaptation_VonKries(\n",
    "    XYZ_w=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50'])),\n",
    "    XYZ_wr=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])),\n",
    "    transform='Bradford',\n",
    ")\n",
    "# Transform from w to wr, the naming is arbitrary.\n",
    "# This produce M_{cat} = M_A^{-1} @ S @M_A, where M_A is Bradford matrix and S is scaling matrix depending on src. and dest. illuminant.\n",
    "XYZ_D65_values_bradford = XYZ_D50_values @ color_correction_mtx_bradford.T\n",
    "\n",
    "# Method 3. Change illuminant under XYZ using CAT02\n",
    "color_correction_mtx_cat02 = colour.adaptation.matrix_chromatic_adaptation_VonKries(\n",
    "    XYZ_w=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50'])),\n",
    "    XYZ_wr=colour.xyY_to_XYZ(colour.xy_to_xyY(colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])),\n",
    "    transform='CAT02',\n",
    ")\n",
    "XYZ_D65_values_cat02 = XYZ_D50_values @ color_correction_mtx_cat02.T\n",
    "\n",
    "# print(XYZ_D65_values)\n",
    "print('White patch(0.05D):')\n",
    "print(f'Identical xy: {colour.XYZ_to_xy(XYZ_D65_values_identical[18])}')\n",
    "print(f'Bradford xy: {colour.XYZ_to_xy(XYZ_D65_values_bradford[18])}') # the brightest white patch\n",
    "print(f'CAT02 xy: {colour.XYZ_to_xy(XYZ_D65_values_cat02[18])}')\n",
    "# Here we could see the difference by using Bradford and Identical matrix in von Keris adaptation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8be6d4",
   "metadata": {},
   "source": [
    "#### a2. Observation\n",
    "For dE calculation, we need Lab values again, which requires XYZ -> Lab transformation with illuminant again.\\\n",
    "If the XYZ->Lab inverse path is not the same with the forward one, dE increases prominantly.\n",
    "\n",
    "For the three method mentioned above, we should **carefully calculate back** to Lab in order to get the accurate dE,\\\n",
    "which reflects the actual residual error introduced by the color correction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44224012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.76300704  0.78461623  2.55468098  1.27930158  2.1124803   0.36321578]\n",
      " [ 1.27623702  4.2126116   0.74909598  1.02017003  1.98745382  2.14843468]\n",
      " [ 4.65064181  1.03465616  0.78876897  2.62805336  0.48428062  2.14900997]\n",
      " [ 0.37530771  0.05705085  0.01716734  0.0189219   0.06967623  0.06471169]]\n",
      "dE max: 4.65, min: 0.02, avg: 1.32\n",
      "dE max: 0.00, min: 0.00, avg: 0.00\n",
      "dE max: 0.00, min: 0.00, avg: 0.00\n"
     ]
    }
   ],
   "source": [
    "# The illuminant transformation causes dE:\n",
    "# LabD50 -> XYZD50 -Bradford-> XYZD65 -(Implicitly Identical) -> LabD50\n",
    "dE_demo_1 = colour.delta_E(lab_values_row_first, colour.XYZ_to_Lab(XYZ_D65_values_bradford, illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])).reshape(4,6)\n",
    "print(dE_demo_1)\n",
    "print(f'dE max: {np.max(dE_demo_1):.2f}, min: {np.min(dE_demo_1):.2f}, avg: {np.mean(dE_demo_1):.2f}')\n",
    "\n",
    "# It seems like you should do all things inversely to get near 0 dE.\n",
    "dE_demo_2 = colour.delta_E(lab_values_row_first, colour.XYZ_to_Lab(XYZ_D65_values_identical, illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65'])).reshape(4,6)\n",
    "print(f'dE max: {np.max(dE_demo_2):.2f}, min: {np.min(dE_demo_2):.2f}, avg: {np.mean(dE_demo_2):.2f}')\n",
    "\n",
    "dE_demo_3 = colour.delta_E(lab_values_row_first, \n",
    "                           colour.XYZ_to_Lab(XYZ_D65_values_bradford @ np.linalg.inv(color_correction_mtx_bradford).T, \n",
    "                                             illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                             )\n",
    "                           ).reshape(4,6)\n",
    "print(f'dE max: {np.max(dE_demo_3):.2f}, min: {np.min(dE_demo_3):.2f}, avg: {np.mean(dE_demo_3):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0150613",
   "metadata": {},
   "source": [
    "#### b. Acquire CC24 measurements from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c78958b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define essential parameters\n",
    "\n",
    "wb_params = (1.87217887201, 1.27358336204, 1.0, -16.2625453031, -13.099179932, 0.0) # or awb_params calculated before\n",
    "repeats = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0373f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera.open: Camera supports 2 pixel format(s)\n",
      "Camera.open: Pixel format 0: Bayer BG 8bit (1Bpp)\n",
      "Camera.open: Pixel format 1: Bayer BG 12bit Packed (1.5Bpp)\n",
      "Camera.open: Using 12bit pixel format.\n",
      "Camera.open: Timecode disabled. Allocating original image buffer size: 30081024 bytes.\n",
      "Camera.open: Raw start bit = -1\n",
      "RAW Grabbed: img.max(): 4094, img.min(): 32\n",
      "After Debayer: img.max(): 65535, img.min(): 0\n"
     ]
    }
   ],
   "source": [
    "# Acquire preview image\n",
    "\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "\n",
    "mycam.open()\n",
    "raw_img = mycam.grab_raw()\n",
    "mycam.close()\n",
    "# img最大值最小值\n",
    "print(f'RAW Grabbed: img.max(): {raw_img.max()}, img.min(): {raw_img.min()}')\n",
    "img = raw_img - BLC\n",
    "img = raw_wb(img, \n",
    "             *wb_params, \n",
    "             pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "if BAYER_PATTERN == 'RGGB':\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BAYER_RGGB2RGB)\n",
    "elif BAYER_PATTERN == 'BGGR':\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BAYER_BGGR2RGB)\n",
    "print(f'After Debayer: img.max(): {img.max()}, img.min(): {img.min()}')\n",
    "img = img.astype(np.float32) / 65535\n",
    "plt.imshow(img)\n",
    "plt.title('White balanced and debayered linear device RGB image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c0d4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 4 corners of the chart\n",
    "chart_corners = np.array([\n",
    "    [1134, 702],\n",
    "    [1528, 702],\n",
    "    [1134, 1294],\n",
    "    [1528, 1294]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4cecae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch  1: Mean RGB = ('41.22', '25.08', '18.22')\n",
      "Patch  2: Mean RGB = ('150.34', '97.29', '80.87')\n",
      "Patch  3: Mean RGB = ('57.37', '73.93', '103.76')\n",
      "Patch  4: Mean RGB = ('26.79', '30.87', '14.13')\n",
      "Patch  5: Mean RGB = ('78.06', '80.21', '118.74')\n",
      "Patch  6: Mean RGB = ('68.79', '115.54', '106.92')\n",
      "Patch  7: Mean RGB = ('158.40', '63.89', '21.15')\n",
      "Patch  8: Mean RGB = ('42.84', '59.88', '116.95')\n",
      "Patch  9: Mean RGB = ('126.51', '43.08', '44.24')\n",
      "Patch 10: Mean RGB = ('28.36', '23.92', '41.13')\n",
      "Patch 11: Mean RGB = ('84.51', '96.64', '23.67')\n",
      "Patch 12: Mean RGB = ('139.32', '74.76', '17.01')\n",
      "Patch 13: Mean RGB = ('21.62', '35.00', '81.57')\n",
      "Patch 14: Mean RGB = ('26.47', '55.65', '19.69')\n",
      "Patch 15: Mean RGB = ('88.53', '22.20', '19.08')\n",
      "Patch 16: Mean RGB = ('165.12', '110.56', '10.28')\n",
      "Patch 17: Mean RGB = ('102.30', '47.56', '74.87')\n",
      "Patch 18: Mean RGB = ('29.18', '62.84', '90.18')\n",
      "Patch 19: Mean RGB = ('250.96', '245.48', '239.97')\n",
      "Patch 20: Mean RGB = ('159.94', '159.97', '159.69')\n",
      "Patch 21: Mean RGB = ('98.08', '98.83', '99.51')\n",
      "Patch 22: Mean RGB = ('48.45', '48.48', '48.44')\n",
      "Patch 23: Mean RGB = ('20.60', '21.14', '21.20')\n",
      "Patch 24: Mean RGB = ('5.96', '6.30', '6.04')\n"
     ]
    }
   ],
   "source": [
    "# Extract 24 patches using correction_utils\n",
    "\n",
    "from correction_utils import calculate_warped_bboxes, extract_colors_warped_bbox, draw_warped_bboxes\n",
    "# 1. Calculate the warped bboxes on the original image\n",
    "# Since orientation is now locked to landscape, we use 4 rows and 6 columns.\n",
    "warped_bboxes = calculate_warped_bboxes(chart_corners, rows=4, cols=6, margin_percent=0.2)\n",
    "\n",
    "# 2. Extract mean colors directly from the original image `img`\n",
    "device_rgb_values_sample = extract_colors_warped_bbox(img, warped_bboxes)\n",
    "\n",
    "# 3. Visualize the bboxes\n",
    "# Draw the warped bboxes on the original, uncorrected image\n",
    "img_with_warped_bboxes = draw_warped_bboxes(img, warped_bboxes)\n",
    "\n",
    "# 4. Print the values\n",
    "for i, rgb in enumerate(device_rgb_values_sample):\n",
    "    rgb_255 = tuple(f'{c * 255:.2f}' for c in rgb)\n",
    "    print(f\"Patch {i+1:2d}: Mean RGB = {rgb_255}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img_with_warped_bboxes)\n",
    "plt.title(\"Warped BBoxes on Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48959cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire repeat measurements\n",
    "\n",
    "from correction_utils import suppress_output\n",
    "raw_wb_slience = suppress_output(raw_wb)\n",
    "\n",
    "DevList = mvsdk.CameraEnumerateDevice()\n",
    "mycam = Camera(DevList[0], EXPOSURE_TIME, gain=1, hibitdepth=1)\n",
    "mycam.open()\n",
    "\n",
    "wb_debayered_imgs = []\n",
    "for i in range(repeats):\n",
    "    raw_img = mycam.grab_raw()\n",
    "\n",
    "    # WB + Debayer\n",
    "    img = raw_img - BLC\n",
    "    img = raw_wb_slience(img, \n",
    "                *wb_params, \n",
    "                pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "    if BAYER_PATTERN == 'RGGB':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_RG2RGB)\n",
    "    elif BAYER_PATTERN == 'BGGR':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_BG2RGB)\n",
    "\n",
    "    img = img.astype(np.float32) / 65535\n",
    "\n",
    "    wb_debayered_imgs.append(img)\n",
    "mycam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00950f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or using measurements from awb run.\n",
    "from correction_utils import suppress_output\n",
    "raw_wb_slience = suppress_output(raw_wb)\n",
    "\n",
    "wb_debayered_imgs = []\n",
    "for raw_img in imgs:\n",
    "    # WB + Debayer\n",
    "    img = raw_img - BLC\n",
    "    img = raw_wb_slience(img, \n",
    "                *wb_params, \n",
    "                pattern=BAYER_PATTERN, clip_max_level=ADC_MAX_LEVEL-BLC)\n",
    "    if BAYER_PATTERN == 'RGGB':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_RG2RGB)\n",
    "    elif BAYER_PATTERN == 'BGGR':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BAYER_BG2RGB)\n",
    "\n",
    "    img = img.astype(np.float32) / 65535\n",
    "    wb_debayered_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ede62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_rgb_values_np.shape: (100, 24, 3)\n"
     ]
    }
   ],
   "source": [
    "# Run color extraction from 24 patches\n",
    "device_rgb_values_list = []\n",
    "for img in wb_debayered_imgs:\n",
    "    device_rgb_values = extract_colors_warped_bbox(img, warped_bboxes)\n",
    "    device_rgb_values_list.append(device_rgb_values)\n",
    "device_rgb_values_np = np.array(device_rgb_values_list)\n",
    "print(f'device_rgb_values_np.shape: {device_rgb_values_np.shape}')\n",
    "device_rgb_values = np.mean(device_rgb_values_np, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a1d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correction matrix (so called Forward Matrix in DNG glossary)\n",
    "\n",
    "fwd_mtx_identical = colour.characterisation.matrix_colour_correction_Cheung2004(device_rgb_values, XYZ_D65_values_identical)\n",
    "fwd_mtx_bradford = colour.characterisation.matrix_colour_correction_Cheung2004(device_rgb_values, XYZ_D65_values_bradford)\n",
    "fwd_mtx_cat02 = colour.characterisation.matrix_colour_correction_Cheung2004(device_rgb_values, XYZ_D65_values_cat02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57399854",
   "metadata": {},
   "source": [
    "We could evaluate the quality of colour correction matrix by calculating $dE_{00}$ between corrected and original colours.\n",
    "\n",
    "The corrected color should be carefully inversed to $Lab_{D50}$. \\\n",
    "Once the inversion is correct, the dE value should only be affected by the colour correction matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b984a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dE00_identical: \n",
      "[[ 1.96578868  1.34830422  1.33780362  1.13119077  2.98306855  3.0142573 ]\n",
      " [ 3.05631698  1.91625769  2.6023089   2.65048287  1.69918594  1.80168823]\n",
      " [ 3.80077929  2.79113842  3.00361289  0.36410477  2.67821099  5.35315001]\n",
      " [ 1.9915914   1.66447423  1.09607302  1.30699857  1.75533823  3.69320372]]\n",
      "  dE max: 5.35, min: 0.36, avg: 2.29\n",
      "dE00_bradford: \n",
      "[[ 1.96578868  1.34830422  1.33780362  1.13119077  2.98306855  3.0142573 ]\n",
      " [ 3.05631698  1.91625769  2.6023089   2.65048287  1.69918594  1.80168823]\n",
      " [ 3.80077929  2.79113842  3.00361289  0.36410477  2.67821099  5.35315001]\n",
      " [ 1.9915914   1.66447423  1.09607302  1.30699857  1.75533823  3.69320372]]\n",
      "  dE max: 5.35, min: 0.36, avg: 2.29\n",
      "dE00_cat02: \n",
      "[[ 1.96578868  1.34830422  1.33780362  1.13119077  2.98306855  3.0142573 ]\n",
      " [ 3.05631698  1.91625769  2.6023089   2.65048287  1.69918594  1.80168823]\n",
      " [ 3.80077929  2.79113842  3.00361289  0.36410477  2.67821099  5.35315001]\n",
      " [ 1.9915914   1.66447423  1.09607302  1.30699857  1.75533823  3.69320372]]\n",
      "  dE max: 5.35, min: 0.36, avg: 2.29\n"
     ]
    }
   ],
   "source": [
    "# Calculate dE00 of nominal values and corrected values\n",
    "\n",
    "CC24_XYZ_corrected_identical = device_rgb_values @ fwd_mtx_identical.T\n",
    "CC24_XYZ_corrected_bradford = device_rgb_values @ fwd_mtx_bradford.T\n",
    "CC24_XYZ_corrected_cat02 = device_rgb_values @ fwd_mtx_cat02.T\n",
    "\n",
    "dE00_identical = colour.delta_E(lab_values_row_first, \n",
    "                      colour.XYZ_to_Lab(CC24_XYZ_corrected_identical, \n",
    "                                        illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65']\n",
    "                                        )\n",
    "                     )\n",
    "dE00_bradford = colour.delta_E(lab_values_row_first, \n",
    "                      colour.XYZ_to_Lab(CC24_XYZ_corrected_bradford @ np.linalg.inv(color_correction_mtx_bradford).T, \n",
    "                                        illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                        )\n",
    "                     )\n",
    "dE00_cat02 = colour.delta_E(lab_values_row_first, \n",
    "                      colour.XYZ_to_Lab(CC24_XYZ_corrected_cat02 @ np.linalg.inv(color_correction_mtx_cat02).T, \n",
    "                                        illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                        )\n",
    "                     )\n",
    "\n",
    "print(f'dE00_identical: \\n{dE00_identical.reshape(4,6)}')\n",
    "print(f'  dE max: {np.max(dE00_identical):.2f}, min: {np.min(dE00_identical):.2f}, avg: {np.mean(dE00_identical):.2f}')\n",
    "print(f'dE00_bradford: \\n{dE00_bradford.reshape(4,6)}')\n",
    "print(f'  dE max: {np.max(dE00_bradford):.2f}, min: {np.min(dE00_bradford):.2f}, avg: {np.mean(dE00_bradford):.2f}')\n",
    "print(f'dE00_cat02: \\n{dE00_cat02.reshape(4,6)}')\n",
    "print(f'  dE max: {np.max(dE00_cat02):.2f}, min: {np.min(dE00_cat02):.2f}, avg: {np.mean(dE00_cat02):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9db5f037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct inversion of Bradford to Lab at D65:\n",
      "  dE max: 6.93, min: 1.09, avg: 2.67\n",
      "Direct inversion of CAT02 to Lab at D65:\n",
      "  dE max: 6.92, min: 1.08, avg: 2.68\n"
     ]
    }
   ],
   "source": [
    "# If the Lab value is not perfectly inverse, it may can reflect the actual performance\n",
    "dE00_bradford_direct_lab = colour.delta_E(lab_values_row_first, \n",
    "                             colour.XYZ_to_Lab(CC24_XYZ_corrected_bradford, \n",
    "                               illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65']\n",
    "                               )\n",
    "                             )\n",
    "dE00_cat02_direct_lab = colour.delta_E(lab_values_row_first, \n",
    "                             colour.XYZ_to_Lab(CC24_XYZ_corrected_cat02, \n",
    "                               illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D65']\n",
    "                               )\n",
    "                             )\n",
    "print('Direct inversion of Bradford to Lab at D65:')\n",
    "print(f'  dE max: {np.max(dE00_bradford_direct_lab):.2f}, min: {np.min(dE00_bradford_direct_lab):.2f}, avg: {np.mean(dE00_bradford_direct_lab):.2f}')\n",
    "print('Direct inversion of CAT02 to Lab at D65:')\n",
    "print(f'  dE max: {np.max(dE00_cat02_direct_lab):.2f}, min: {np.min(dE00_cat02_direct_lab):.2f}, avg: {np.mean(dE00_cat02_direct_lab):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc2bd8",
   "metadata": {},
   "source": [
    "But the sRGB value **will** be affected by different chromatic adaptation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c412025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[109  78  64 111  78  64]\n",
      " [199 148 131 202 148 131]\n",
      " [ 93 123 157  85 124 157]\n",
      " [ 87 105  62  91 105  63]\n",
      " [141 134 182 135 135 182]\n",
      " [113 197 182 111 197 182]\n",
      " [211 119  39 216 119  39]\n",
      " [ 60  90 164  31  92 164]\n",
      " [205  86 102 207  87 102]\n",
      " [ 85  59 105  81  60 105]\n",
      " [161 192  70 170 191  73]\n",
      " [234 167  50 241 166  52]\n",
      " [  9  56 131 -61  58 130]\n",
      " [ 65 139  69  72 138  70]\n",
      " [184  56  67 186  56  66]\n",
      " [236 198  -3 245 197  10]\n",
      " [196  88 151 195  90 151]\n",
      " [ 23 141 173 -59 141 173]\n",
      " [232 232 226 233 232 226]\n",
      " [195 198 196 195 198 196]\n",
      " [159 163 162 159 163 162]\n",
      " [118 120 119 118 120 119]\n",
      " [ 78  82  83  78  82  83]\n",
      " [ 41  47  49  41  47  49]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate sRGB value in 8bit using different adaptation transforms\n",
    "CC24_sRGB_corrected_identical = colour.XYZ_to_sRGB(CC24_XYZ_corrected_identical)\n",
    "CC24_sRGB_corrected_bradford = colour.XYZ_to_sRGB(CC24_XYZ_corrected_bradford)\n",
    "\n",
    "print(np.hstack(((CC24_sRGB_corrected_bradford * 255).astype(int), \n",
    "      (CC24_sRGB_corrected_identical * 255).astype(int)))\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e1ded6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.49089543535..1.10486705249].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.42439499721..1.08545231896].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.25408739847..1.08384252532].\n"
     ]
    }
   ],
   "source": [
    "# Validate correction by performing a forward transformation to sRGB\n",
    "img_XYZ_corrected_identical = img @ fwd_mtx_identical.T\n",
    "img_XYZ_corrected_bradford = img @ fwd_mtx_bradford.T\n",
    "img_XYZ_corrected_cat02 = img @ fwd_mtx_cat02.T\n",
    "\n",
    "img_sRGB_identical = colour.XYZ_to_sRGB(img_XYZ_corrected_identical, chromatic_adaptation_transform='Bradford', apply_cctf_encoding=True)\n",
    "img_sRGB_bradford = colour.XYZ_to_sRGB(img_XYZ_corrected_bradford, chromatic_adaptation_transform='Bradford', apply_cctf_encoding=True)\n",
    "img_sRGB_cat02 = colour.XYZ_to_sRGB(img_XYZ_corrected_cat02, chromatic_adaptation_transform='Bradford', apply_cctf_encoding=True)\n",
    "# The chromatic_adaptation_transform should not affect anything since the sRGB is D65 based.\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image (linear, device RGB)')\n",
    "ax1.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax1.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax2.imshow(img_sRGB_identical)\n",
    "ax2.set_title('Corrected Image (Implicit Identical)')\n",
    "ax2.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax2.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax3.imshow(img_sRGB_bradford)\n",
    "ax3.set_title('Corrected Image (Bradford)')\n",
    "ax3.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax3.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax4.imshow(img_sRGB_cat02)\n",
    "ax4.set_title('Corrected Image (CAT02)')\n",
    "ax4.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax4.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5e877",
   "metadata": {},
   "source": [
    "#### b2. Conclusion\n",
    "Visually, the CAT02 method is the best.\n",
    "\n",
    "We visualize the whole process of RAW development here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b84a01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative efficient calculation (using CAT02 as example) showing the whole process:\n",
    "\n",
    "from correction_utils import linear_to_srgb\n",
    "\n",
    "device_RGB_to_linear_sRGB = colour.RGB_COLOURSPACES['sRGB'].matrix_XYZ_to_RGB @ fwd_mtx_cat02\n",
    "img_sRGB_cat02_linear = np.clip(img @ device_RGB_to_linear_sRGB.T, 0, 1)\n",
    "img_sRGB_cat02 = linear_to_srgb(img_sRGB_cat02_linear)\n",
    "\n",
    "fig, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(2, 4, figsize=(16, 10))\n",
    "ax1.imshow(raw_img)\n",
    "ax1.set_title(\"RAW Image\")\n",
    "ax1.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax1.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax2.imshow(img)\n",
    "ax2.set_title(\"WB+Debayered Image (Linear)\")\n",
    "ax2.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax2.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax3.imshow(img_sRGB_cat02_linear)\n",
    "ax3.set_title(\"CAT02+Cheung2004 Fwd Corr. Img. (Linear)\")\n",
    "ax3.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax3.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax4.imshow(img_sRGB_cat02)\n",
    "ax4.set_title(\"CAT02+Cheung2004 Fwd Corr. Img. (sRGB)\")\n",
    "ax4.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax4.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax5.imshow(cv2.cvtColor(raw_img, cv2.COLOR_BAYER_RG2RGB)/4096)\n",
    "ax5.set_title('Debayer Only (Device RGB)')\n",
    "ax5.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax5.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax6.imshow(linear_to_srgb(img))\n",
    "ax6.set_title('WB+Debayered in sRGB gamma')\n",
    "ax6.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax6.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6b7f7",
   "metadata": {},
   "source": [
    "#### b3. Optimize calculation process to accelerate the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e4a2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe a C extension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44548b9c",
   "metadata": {},
   "source": [
    "#### c. Using customized loss function (dE2000 based) to calculate forward matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b7e6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  100, Loss (dE2000**3): 16.6669\n",
      "Iteration  200, Loss (dE2000**3): 16.0623\n",
      "Iteration  300, Loss (dE2000**3): 16.0596\n",
      "Iteration  400, Loss (dE2000**3): 16.0499\n",
      "Iteration  500, Loss (dE2000**3): 16.0427\n",
      "Iteration  600, Loss (dE2000**3): 16.0398\n",
      "Iteration  700, Loss (dE2000**3): 16.0228\n",
      "Iteration  800, Loss (dE2000**3): 16.0218\n",
      "Iteration  900, Loss (dE2000**3): 16.0217\n",
      "\n",
      "Optimization finished.\n",
      "Final Loss (dE2000**3): 16.0217\n"
     ]
    }
   ],
   "source": [
    "# A good initial value is essential for better dE.\n",
    "\n",
    "sigma_init = 0.01\n",
    "\n",
    "from correction_utils import forward_matrix_slover\n",
    "\n",
    "fwd_mtx_custom_solver, final_loss = forward_matrix_slover(device_rgb_values, XYZ_D50_values, \n",
    "                                                   illuminant='D50',\n",
    "                                                   initial_matrix=fwd_mtx_cat02+np.random.normal(0, sigma_init, size=(3,3)),\n",
    "                                                   extra_illuminant_transform_XYZ=np.linalg.inv(color_correction_mtx_cat02),\n",
    "                                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1cdc279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom forward_matrix: \n",
      "[[ 0.51520722  0.43302808 -0.0720398 ]\n",
      " [ 0.17274142  1.12415422 -0.36759659]\n",
      " [-0.07615428  0.14034464  0.93096758]]\n",
      "fwd_mtx by colour-science: \n",
      "[[ 0.49468862  0.4820519  -0.0780434 ]\n",
      " [ 0.1701273   1.14376065 -0.35781853]\n",
      " [-0.06787128  0.13264455  0.96712382]]\n",
      "dE00 from custom forward matrix:\n",
      "[ 1.54988667  0.77919942  0.4225414   1.67787893  2.97112959  2.14182385\n",
      "  3.04265187  1.61681218  2.41465966  1.71438114  1.63516008  1.6312734\n",
      "  3.91349094  2.98096217  2.78082697  0.72169169  2.16390433  4.18873655\n",
      "  2.89368925  1.84503772  0.97022124  1.232856    1.67893981  3.6663996 ]\n",
      "  dE max: 4.19, min: 0.42, avg: 2.11\n",
      "dE00 from CAT02:\n",
      "[ 2.70662114  1.66886312  2.6484186   2.14130687  4.32537903  3.1613709\n",
      "  4.08665526  2.548449    2.32394747  1.32350839  2.80536337  2.23254297\n",
      "  3.30330363  2.69932984  3.21808881  2.45958912  2.54332861  6.91824282\n",
      "  1.96482815  1.70601426  1.0826569   1.33952372  1.60683865  3.44574803]\n",
      "  dE max: 6.92, min: 1.08, avg: 2.68\n"
     ]
    }
   ],
   "source": [
    "# Print and render results\n",
    "print('custom forward_matrix: ')\n",
    "print(fwd_mtx_custom_solver)\n",
    "\n",
    "print('fwd_mtx by colour-science: ')\n",
    "print(fwd_mtx_cat02)\n",
    "\n",
    "CC24_XYZ_corrected_custom_fwd = device_rgb_values @ fwd_mtx_custom_solver.T\n",
    "\n",
    "dE00_custom_fwd_direct_lab = colour.delta_E(lab_values_row_first, \n",
    "                               colour.XYZ_to_Lab(CC24_XYZ_corrected_custom_fwd @ np.linalg.inv(color_correction_mtx_cat02).T, \n",
    "                                 illuminant=colour.CCS_ILLUMINANTS['CIE 1931 2 Degree Standard Observer']['D50']\n",
    "                                 )\n",
    "                               )\n",
    "\n",
    "print('dE00 from custom forward matrix:')\n",
    "print(dE00_custom_fwd_direct_lab)\n",
    "print(f'  dE max: {np.max(dE00_custom_fwd_direct_lab):.2f}, min: {np.min(dE00_custom_fwd_direct_lab):.2f}, avg: {np.mean(dE00_custom_fwd_direct_lab):.2f}')\n",
    "print('dE00 from CAT02:')\n",
    "print(dE00_cat02_direct_lab)\n",
    "print(f'  dE max: {np.max(dE00_cat02_direct_lab):.2f}, min: {np.min(dE00_cat02_direct_lab):.2f}, avg: {np.mean(dE00_cat02_direct_lab):.2f}')\n",
    "\n",
    "img_sRGB_custom_fwd = linear_to_srgb(np.clip(img @ fwd_mtx_custom_solver.T @ colour.RGB_COLOURSPACES['sRGB'].matrix_XYZ_to_RGB.T, 0, 1))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(img_sRGB_custom_fwd)\n",
    "ax1.set_title(\"Custom Forward Matrix\")\n",
    "ax1.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax1.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax1.axis('off')\n",
    "ax2.imshow(img_sRGB_cat02)\n",
    "ax2.set_title(\"CAT02 Forward Matrix\")\n",
    "ax2.set_xlim(chart_corners[:, 0].min(), chart_corners[:, 0].max())\n",
    "ax2.set_ylim(chart_corners[:, 1].max(), chart_corners[:, 1].min())\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e92359c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bases of the device RGB space in XYZ color model.\n",
    "\n",
    "# Note on linear algebra: the conversion matrix which map points from space A to B, \n",
    "# literally equals to horizontal stacks of bases of space A in the coordinates of space B.\n",
    "# (Here, we assume all vectors are vertically arranged.)\n",
    "\n",
    "fig, ax = colour.plotting.plot_RGB_colourspaces_gamuts('sRGB', 'CIE XYZ')\n",
    "ax.scatter(fwd_mtx_custom_solver[:, 0], fwd_mtx_custom_solver[:, 1], fwd_mtx_custom_solver[:, 2], c = ('red', 'green', 'blue'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a574748",
   "metadata": {},
   "source": [
    "#### d. Save correction results in numpy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62a23c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLC': 32, 'ADC_MAX_LEVEL': 4095, 'wb_params': (1.0, 1.30625734229, 1.63808680867, 0.0, -6.91589560617, -1.8556998082), 'fwd_mtx': array([[ 0.51520722,  0.43302808, -0.0720398 ],\n",
      "       [ 0.17274142,  1.12415422, -0.36759659],\n",
      "       [-0.07615428,  0.14034464,  0.93096758]]), 'Notes': 'D50 15% power, vertical illuminant, 10ms exposure, Analog Gain 1.0, 8mm Lens, IMX264, 5MP'}\n"
     ]
    }
   ],
   "source": [
    "# Save tag: BLC, ADC_MAX_LEVEL, wb_params, fwd_mtx and Notes\n",
    "\n",
    "Notes = 'D50 15% power, vertical illuminant, 10ms exposure, Analog Gain 1.0, 8mm Lens, IMX264, 5MP'\n",
    "\n",
    "np.save('correction_results.npy', {'BLC': BLC, 'ADC_MAX_LEVEL': ADC_MAX_LEVEL,\n",
    "                                   'wb_params': wb_params, 'fwd_mtx': fwd_mtx_custom_solver, \n",
    "                                   'Notes': Notes\n",
    "                                   })\n",
    "\n",
    "# Read back and check\n",
    "data = np.load('correction_results.npy', allow_pickle=True).item()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c123773",
   "metadata": {},
   "source": [
    "`wb_params`: (R_gain, G_gain, B_gain, R_dBLC, G_dBLC, B_dBLC)\n",
    "\n",
    "`fwd_mtx`: Transform from device RGB to $XYZ$ in given illuminant (e.g. D50). \n",
    "The user should calculate chromatic (illuminant) adaptation and $XYZ$->sRGB itself.\n",
    "如果已经wb，是否还需要改变fwd_mtx? 可能有微调。测试一下。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
